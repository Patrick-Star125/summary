## 大语言模型(LLM)

ChatGPT出现后，人们开始重新关注大语言模型在工业界的作用，其中最广泛讨论的话题就是ChatGPT能否取代Google、百度这样的传统搜索引擎？

### 经济

关于大语言模型替代搜索引擎，在经济可行性上有一篇来自oneflow的分析：[ChatGPT背后的经济账](https://mp.weixin.qq.com/s/aAg1ptEkQ6ahdjs-3s_g3A)

**重点概览：**

- **LLM驱动的搜索已经在经济上可行**：粗略估计，在现有搜索成本结构的基础上，高性能LLM驱动搜索的成本约占当下预估广告收入/查询的15%。
- **但经济可行并不意味着经济合理**：LLM驱动搜索的单位经济性是有利可图的，但对于拥有超1000亿美元搜索收入的现有搜索引擎来说，添加此功能可能意味着超100亿美元的额外成本。
- **其他新兴的LLM驱动业务利润很高**：比如Jasper.ai使用LLM生成文案，很可能有SaaS服务那样的毛利率（超75%）。
- **对于大公司而言，训练LLM（即使是从头开始）的成本并不高**：如今，在公有云中训练GPT-3仅需花费约140万美元，即使是像PaLM这样最先进的模型也只需花费约1120万美元。
- **LLM的成本可能会显著下降**：自GPT-3发布的两年半时间里，与GPT-3性能相当的模型的训练和推理成本下降了约80%。
- **数据是LLM性能的新瓶颈**：与增加高质量训练数据集的大小相比，增加模型参数的数量能获得的边际收益越来越小。

总的来说，从**经济角度**来看，通过粗略估算，将高性能LLM纳入搜索将花费约15%的查询收入，这表明该技术的部署已经切实可行。从**市场角度**，引入大预言模型很可能对谷歌当前的市场主导地位产生较大的影响，与谷歌相比，微软搜索引擎的市场份额要低得多，但是微软并未亏损。因此，如果微软能够成功地从谷歌手中夺取搜索市场份额，那么即使现有查询成本更高，微软仍然能够获得极高的利润。

**LLM的盈利能力初具雏形，训练成本也将进一步降低**。对于其他产品，通过部署LLM已经可以通过SaaS来盈利，毛利率可能远高于75%。如今在公有云中仅需约140万美元即可对GPT-3进行训练，而且即使是SOTA模型（如PaLM，约1120万美元）的训练成本也不会太高。在过去的两年半里，类似GPT-3等模型的训练成本下降了80%以上。换句话说，训练大语言模型并不便宜，但也没那么烧钱，训练大语言模型需要大量的前期投入，但这些投入会逐年获得回报。更近一步，Chinchilla论文表明，在未来，相比资金，高质量数据会成为训练LLM的新兴稀缺资源之一，因为扩展模型参数数量带来的回报是递减的。

