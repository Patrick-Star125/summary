### 目标检测(Object -Detection)

**批规范化(Batch Normalization)**

批规范化操作，不仅加快了模型收敛速度，而且更重要的是在一定程度缓解了深层网络的一个难题“梯度弥散”，从而使得训练深层网络模型更加容易和稳定。另外，批规范化操作不光适用于深层网络，对传统的较浅层网络而言，批规范化也能对网络泛化性能起到一定提升作用。

**MAP**

MAP中M表示取平均，AP即在目标检测中一个类在不同confidence下precision和recall所围成的面积

![](http://1.14.100.228:8002/images/2022/01/10/map.png)

其中， Precision翻译成中文就是“**分类器认为是正类并且确实是正类的部分占所有分类器认为是正类的比例**”。Recall翻译成中文就是“**分类器认为是正类并且确实是正类的部分占所有确实是正类的比例**”。 

为什么用map？目标检测中置信度是核心概念，单个指标会使得对模型效果的评价片面化，二者进行结合才是评价的正确方法。

#### YoLo

论文思想

* 将图片分为SxS的网格，如果object的中心位于某个网格中，那么该网格就负责预测这个object
* 每个网格预测B个bounding box，每个box预测xywh和confidence值(IOU)
* 在每个卷积层后加上BN层，对于训练收敛有巨大的帮助，并具有一定防过拟合的正则化作用，使用BN后可以不用dropout
* 使用更高的分辨率输入图片
* 采用anchor，能够使网络更好的收敛，使recall上升，模型更好调
* 基于训练集box，采用k-means获取anchor
* 将低层特征图与高层特征图融合，使网络能更好的检测小目标
* 每迭代10个batch，网络就随机输入一个32倍数的图像大小
* 误差计算并没有被作者明确给出，可以自己修改

**交并比(IOU-intersection over union)**

两个bounding box的交集与并集比，为1则完全重合，当一个gird cell检测anchor与目标边界框IOU小于阈值时或经过NMS(Non-Maximum-Suppression)定为不能作为object的中心box，将该grid cell定为负样本，反之，定为正样本

**anchor boxes(锚框)**

anchor boxes概念的提出是为了解决同一个grid cell中有多个object的中心存在，预先定义一定数量一定形状的bounding box，当输入图像时，令object与anchor box中IOU最大的box作为该object的输出

**非极大值抑制(Non-Maximum-Suppression)**

非极大值抑制，在计算机视觉任务中得到了广泛的应用，例如边缘检测、人脸检测、目标检测（DPM，YOLO，SSD，Faster R-CNN）等。 在同一目标的位置上会产生大量的候选框， 需要利用非极大值抑制找到最佳的目标边界框，消除冗余的边界框 。

![](http://1.14.100.228:8002/images/2022/01/10/nms.jpg)

**残差块(Res-Block)**

在yolov3网络中，卷积深度达到53，如此深的网络可能会造成高层特征提取不全的问题，因此引入残差块，将X层feature map进行卷积-BN-ReLu-卷积-BN-深度相加与X+L层feature map相加，其中可能会出现维度不同的问题，因此需要1x1卷积层进行升维或降维

<u>YOLOv4相对于之前三个版本有很大提升，使用了2020年以前在目标检测上有效的许多技术，综合性、技术性、研究性很强，故单独分析这些技术作为学习</u>

**cutmix**

**mosaic**

**Stylized-ImageNet**

**label smooth**

**DropBlock**

对每一个feature map都进行随机区域的删除，这种方式其实是借鉴**2017年的cutout数据增强**的方式，cutout是将输入图像的部分区域清零，而Dropblock则是将Cutout应用到每一个特征图。而且并不是用固定的归零比率，而是在训练时以一个小的比率开始，随着训练过程**线性的增加这个比率**。

**CIOU_loss**

在了解CIOU_loss之前，先了解其原型，即DIOU_loss、GIOU_loss、IOU_loss

IOU_Loss：主要考虑检测框和目标框重叠面积。

GIOU_Loss：在IOU的基础上，解决边界框不重合时的问题。

DIOU_Loss：在IOU和GIOU的基础上，考虑边界框中心点距离的信息。

CIOU_Loss：在DIOU的基础上，考虑边界框宽高比的尺度信息。

Yolov4中采用了CIOU_Loss的回归方式，使得预测框回归的**速度和精度**更高一些。

**网络结构**

YOLOv1

YOLOv2

YOLOv3

**YOLOv4**

![](http://1.14.100.228:8002/images/2022/01/10/yolov4.png)

主要的网络结构图里都有简图，prediction和YOLOv3类似的head，只是分支来源不同，这里说一下PANet，即图中应用了上采样的部分，这里同样应用了特征融合技术

在目标检测任务中，融合不同尺度的特征是提升性能的一个重要手段，低层特征分辨率更高，包含更多**位置、细节信息**，但是由于经过的卷积更少，其**语义性更低，噪声更多**。高层特征**具有更强的语义信息，但是分辨率很低，对细节的感知能力较差**。 

## 目标跟踪

大体上有许多方面的知识可以继承于目标检测，从结果上看最核心的区别就是，output中多出了一个**物体ID**的维度

**任务差异**

目标检测任务需要在目标检测的基础上对视频流帧与帧之间的联系构建模型

![](http://1.14.100.228:8002/images/2022/01/10/145f3d7c253175d80bc2ac1846f72063.png)

**Separate Detection and Embedding**

**ROI：**

**Re-ID图片静态特征提取：**

**动作预测特征：**

**相似度计算：**

**ID数据匹配：**

**Joint Detection and Tracking**

将检测器和Re-ID的特征提取器合并，同时输出检测框和相应检测框的位置特征。再将位置、动作特征一起进入相似度计算模块中。

### Deepsort

![](http://1.14.100.228:8002/images/2022/01/10/deepsort.png)

位置定位之后，，将图像送入Re-ID模型，得到目标特征向量

![](http://1.14.100.228:8002/images/2022/01/10/Re-ID.png)

使用运用广泛的卡尔曼滤波算法来进行运动状态估计：1.根据历史帧得出的估计值2.根据检测器得出的观测值

利用卡尔曼滤波来综合估计值和观测值得到更加准确的值

![](http://1.14.100.228:8002/images/2022/01/10/54a038a94728bee14195aeeca34355f5.png)

![](http://1.14.100.228:8002/images/2022/01/11/030e0c5ddb10305a252c7f1ffdb7dfe2.png)

![](http://1.14.100.228:8002/images/2022/01/11/238dfed2f668700bb8deddb11c613616.png)





