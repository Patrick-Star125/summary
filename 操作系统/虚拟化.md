## 抽象进程

![](http://1.14.100.228:8002/images/2022/04/05/20220405171419.png)

**描述进程**

操作系统的终极目标即是使程序更加简单易用，为了达成这一目的，我们需要对程序本身进行抽象。**进程（process）**就是运行程序的主要操作系统抽象，在任何时候，进程都可以用它的三个状态来描述。

* 地址空间中的内存内容
* CPU寄存器的内容（程序计数器、堆栈指针、帧栈指针）
  * ![](http://1.14.100.228:8002/images/2022/04/05/20220405144720.png)

* 关于IO的信息（已打开的文件）

**进程创建**

一个进程的创建需要做很多事情，首先它要把代码和静态数据加载到内存，然后初始化堆区（由代码主动分配的内存区域），再初始化IO相关的任务（标准流）。通过这些操作后，操作系统为程序的执行创建好了条件。

![](http://1.14.100.228:8002/images/2022/04/05/20220405164003.png)

**进程状态**

进程可以处于多种不同的状态之一，包括Running、Ready和Blocked。不同的事件(例如，被调度或被取消调度，或等待 I/O完成）会将进程从这些状态之一转换到另一个状态。

<img src="http://1.14.100.228:8002/images/2022/01/18/20220118223041.png" style="zoom:50%;" />

* Running：进程处于运行状态，正在执行指令
* Ready：进程处于准备运行状态（寄存器与指针就绪，此时占用CPU），但是系统出于某些原因没有选择执行
* Blocked：进程状态被存储起来，处于“沉睡”状态（不占用CPU），例如执行IO时，进程进入Bolcked状态直到IO完成

通过这三个状态，我们可以使进程成为CPU虚拟化技术的基础单位，即通过调节进程的执行顺序来进行计算资源的分配。

**存储进程**

操作系统也是程序，和其它程序一样，它用一些数据结构来跟踪程序运行时的各种相关信息。

进程状态在操作系统中是怎样存储的呢？我们要提到一种数据结构，叫做**进程表**，它包含系统中所有进程的信息，列表中每个条目都存在于有时被称为**进程控制块（processing control block）**的东西中，它实际上只是一个包含特定进程信息的结构。简单来讲，可以是下图所示的结构体。

![](http://1.14.100.228:8002/images/2022/04/05/20220405170029.png)

切换进程时，系统读取进程表中下一个要执行的进程的有关信息，放入寄存器中，此时下一个进程进入Ready状态，直到下一个时间片，CPU开始执行进程指令，进程切换就完成了。

**进程API**

最后，普通进程受操作系统管理，有一些比较通用的API用来管理进程。

| API  |                            Create                            |                           Destroy                            |                            Wait                             |                            Status                            |
| :--: | :----------------------------------------------------------: | :----------------------------------------------------------: | :---------------------------------------------------------: | :----------------------------------------------------------: |
| 说明 | 操作系统必须包含一些创建新进程的方法。当您在shell中键入命令，或双击应用程序图标时，操作系统将被调用，以创建一个新进程来运行您所指示的程序。 | 由于存在创建进程的接口，系统也提供了强制销毁进程的接口。当然，许多进程会运行并在完成时自动退出;然而，当它们没有自动停止时，用户可能希望手动杀死它们，因此，一个界面来停止失控的进程是非常有用的。 | 有时等待进程停止运行是有用的;因此，通常会提供某种等待接口。 | 通常还会有一些接口来获取有关进程的一些状态信息，比如它运行了多长时间，或者它处于什么状态。 |

> 还有一些其它的API，例如，大多数操作系统都提供了某种方法来暂停进程(暂时停止运行)，然后恢复进程(继续运行)

**总结**

我们了解了操作系统最基本的抽象：进程，介绍了它的底层机制，这一部分与虚拟化的关系在于，对计算资源和存储资源的虚拟化就是建立在进程这一概念之上的，通过进程这一概念，每个程序都仿佛拥有自己独立的cpu资源和内存资源。有了这一基础概念，之后我们会学习**时间共享**和**上下文转换**等机制，以此了解进程与进程之间的关系，为后面学习更深一步的进程调度打下基础。

## 运行受限

当CPU虚拟化后，操作系统在许多看似同时运行的作业之间共享CPU，这要求我们设计一些方法来合理的实现虚拟化。自然，有两个方面需要我们仔细考虑，一是性能，如何在开销可接收的情况下实现虚拟化？第二个是控制，我们如何确保操作系统总是能够控制机器资源，而不至于让进程接管机器。这一节我们主要解决第二点。

既然操作系统也是由许多程序组成的，也就是说操作系统本身也是诸多进程的集合。但我们要形成一种共识，普通程序的运行应当受到操作系统的调控，保证其运行受限，防止其做出危害系统软件和硬件的行为。

更具体的说，进程在运行时总是想要占用全部的CPU时间，操作系统如何确保进程不会做任何我们不想让它做的事情，或者说，我们需要一些技术让操作系统：

* 能够在进程想要做不被允许的操作时检测并暂停（终止）它
* 在不占用CPU的情况下也能够切换（终止）普通进程

基于我们对进程的基础认识，我们可以简单描述系统和进程之间的交互关系，如下图所示。接下来我们引入**运行受限（LIMITED DIRECT EXECUTION）**这个概念，在下图的基础上增加一些操作。

![](http://1.14.100.228:8002/images/2022/04/07/20220407132729.png)

我们先直接描述一下运行受限协议的流程，操作系统为CPU套上“保护套”，在开机时操作系统初始化**trap表**并启动中断计时器，让操作系统处于**内核模式**，普通进程处于受限模式。在某些关键的时间点，例如当一个进程发出一个**系统调用**，或者一个**定时器中断**发生时，安排操作系统参与进来，并确保“正确”的事情发生。

这里有三个概念需要进行解释，首先操作系统定义了两种进程状态，**内核的**和**受限的**。顾名思义，内核进程就是操作系统进程，受限进程就是收到操作系统管理的普通进程，相对于内核进程，受限进程无法进行IO，申请CPU资源和占用更多内存。这些都需要通过操作系统进行系统调用来**协助**进行。

>  trap在表现上是一种由异常情况（例如，断点，非法操作码）引起的同步中断，它一开始就在硬件中初始化，多个trap组成trap table。当触发trap则将进入操作系统进程，也就是内核模式来处理异常，这是我们初次接触**硬件协助（hardware support）**

中断计时器是一种定期触发trap的机制，在CPU被用户进程占用时，操作系统是无法主动得到进程的控制权的，这时候硬件通过设置中断计时器来让进程每隔一段时间进行一次中断，帮助操作系统能够在一段时间内获得操作进程和进行system call的能力。

说那么多不如直接看流程图，下图展示了在运行受限的前提下，系统在开机时初始化流程，和运行时系统、硬件、进程三者之间的关系

![](http://1.14.100.228:8002/images/2022/04/06/20220406215749.png)

> 上面那张图非常重要，需要仔细看懂

通过这些基础机制，操作系统只需要处理内核操作和切换用时过长进程即可保证其它进程安全的进行。但是，总是有多个进程同时向操作系统请求cpu占用，操作系统该怎么安排，这是系统能否高效运行的保证。

**注：**进行system call和context switch的时间成本都非常低，但相对CPU执行速度来说不可忽视。

> Based on our observations, the average direct cost of the kernel-level context switch is 0.62\u0016sand the average direct cost of user-level context switch time is 1.18\u0016s.

## 调度策略

我们已经了解了操作系统调度资源的底层策略，如进程的运行等。但是如果要想理解更高级的调度策略（scheduling policies），那么首先要明确我们要解决的是什么问题：**早期**计算机的调度策略是怎样的？调度策略的**关键假设**和**评估指标**是什么？怎样建立一个调度策略的**基本框架**？

我们抽象出一个概念：工作负载（workload）来描述操作系统的所处理的任务也就是调度进程，用作业(job)来描述进程，并且我们假设在操作系统中

1. 每个作业运行相同的时间。
2. 所有的作业同时出现。
3. 一旦启动，每个作业就会一直运行到完成。（这个假设看上去更靠谱一些，但也还是假设）
4. 所有的作业只使用CPU（它们不执行I/O）。
5. 每个作业的运行时是已知的。（这个最离谱，但是这是本次讨论的大前提）

提出假设的原因是我们如果想从零开始构建一个调度策略，首先就要考虑最简单的情况，也就是以上假设都成立的情况（当然这不可能），另外，我们需要一些评估指标来告诉我们设计的调度策略合不合理，这里我们提出两个指标：

* turnaround time = 进程完成时间 - 进程出现时间（对系统友好）

* response time = 进程响应时间 - 进程出现时间（对用户友好）

准备工作都完成了，我们开始正式讨论调度策略的构建。假如系统中工作负载都遵循以上的假设，那么操作系统就可以用十分简单的调度策略来安排CPU资源的使用如**FIFO**策略（假设①成立）

> FIFO是First In, First Out的缩写，顾名思义，操作系统把每个进程都安排运行，先来先服务，问题是显而易见的，假设①不成立的话，如果一个进程占用时间太长，那么后面的进程被无限延后，这将导致系统极其难用。
>
> ![](http://1.14.100.228:8002/images/2022/04/07/20220407203141.png)

还有稍微升级一些的策略：**SJF**策略（假设②成立）

> SJF是Shortest Job First的缩写，基本上就是针对FIFO的缺点，把运行时间最短的放到前面进行，假设②不成立的话，如果有进程在A运行的中间才开始，就要被迫等到A结束才能执行，导致这基本上和FIFO没有区别
>
> ![](http://1.14.100.228:8002/images/2022/04/07/20220407204109.png)

假如我们以turnaround time作为评价体系（考虑系统），那么在假设5成立的情况下，我们应当使用**STCF**调度策略，它的基本思想就是：每当有程序进入运行状态，在当前所有进程中总运行时间最短的对cpu资源进行**抢占**，以此近似最优化turnaround time。

> STCF是Shortest Time-to-Completion First的缩写，和上面描述的一样，它可以解决前两个策略的问题，它的问题是对用户不友好，试想一下假如A进程是一个用户界面程序，那么用户会明显的感觉到程序的卡顿
>
> ![](http://1.14.100.228:8002/images/2022/04/07/20220407204632.png)

假如我们以response time作为评价体系（考虑用户），那么在假设5成立的情况下，我们应当使用**RR**调度策略，它的基本思想就是：选取一个cpu时间的n倍作为基本时间片，然后每隔一个时间片就切换一次进程，这样确保每个进程从开始到结束都有相对良好的响应速度。注意，时间片的选取对响应时间的影响至关重要。但是并不是时间片越短越好，因为上下文切换的时间成本会因此指数级上升。

> RR是Round Robin的缩写，Robin在英语里有侠盗的意思，在这里就是指“好”的抢占
>
> ![](http://1.14.100.228:8002/images/2022/04/07/20220407205047.png)

我们注意到，假如进程有IO任务，那么在它进行IO时，进程处于等待（ready）状态，很浪费CPU资源，CPU可以使用**overlap策略**对IO时间片用其它进程进行抢占。这样可以利用时间片切换进程的特性来使IO对CPU的影响降到很低。

> overlap很重要，这一朴素的思想因其实用性一直沿用至今，之后我们也会在各种地方看到它
>
> ![](http://1.14.100.228:8002/images/2022/04/07/20220407205409.png)

**总结**

这节所学的是调度策略是设计思想，实际操作系统的调度策略十分强大，同时非常复杂。早期调度策略非常简单以至于没有实用性，在假设5成立的情况下，我们可以采用STCF、RR、overlap结合的策略来对进程进行调度，但是RR会大大增加turnaround time，而STCF会增加response time，怎样对他们进行trade-off是构建调度策略的基本框架的关键。

## MLFQ策略

我们已经学习了在假设状态下的最基础调度策略，它们都是为了优化既定指标而粗略设计的调度策略。在实际的操作系统中，调度是一项十分复杂的工作，要同时面对数百个状态不一的进程，还要保证较高的处理速率和较快的响应时间。基于**同时优化两个指标（turnaround time和response time）**的目的，科学家设计了一种策略，叫做Multi-level Feedback Queue(MLFQ)策略。它的核心思想是：关注进程在一段时间内行为，并依此进行处理。

基础的设计是使用多个优先队列，让所有进程都在队列中，并遵循5个最基本的规则：

* 如果进程A所处队列优先级比进程B高，则运行A
* 如果进程A和进程B在同一个队列，则它们之间遵循RR策略，交替运行
* 当有进程产生时，放在最高级的队列中
* 当一个进程用完了在当前队列中的**时间份额**，则切换到下一级队列中
* 在一段时间 **S** 后，所有进程都重置到最高级队列中（Priority Boost）

我们来解释一下它的设计思想，你也许注意到了，MLFQ是真正可以适用于现实系统的调度策略，因为上一节最关键的假设：每个作业的运行时是已知的，总是不成立。因此操作系统面对多个进程的时候，无法一下子得知哪个进程应当被安排到最优先进行，哪个应该是最后进行。解决这一问题的关键是构建一种**基于过程的启发式方法**，也就是在进程运行的过程中通过它的行为判断应该分配多少CPU资源，上面的规则就是基于这个前提构建出来的。

> 实际上这些规则的构建过程十分严谨而且比较复杂，有兴趣的可以看原书第7节

> 启发式方法指人在解决问题时所采取的一种根据经验规则进行发现的方法。其特点是在解决问题时，利用过去的经验，选择已经行之有效的方法，而不是系统地、以确定的步骤去寻求答案。

MLFQ策略成功的实现了turnaround time和response time的双重优化，对于需要长时间运行的进程，能够在S时间后得到一段运行的时间，而交互性强的进程，则总是在较上级的队列中，能够较频繁的访问CPU，但不至于霸占CPU不放。第四条规则让所有进程不管在什么状态下都不能长时间占用CPU，保证了所有进程之间的公平性（fairness）。

在MLFQ策略下的workload如下图所示

![](http://1.14.100.228:8002/images/2022/04/08/20220408105544.png)

由于它优良的性能，许多系统包括UNIX衍生，Solaris、Windows系统都采用不同形式的MLFQ来作为进程的基本调度器。在实际使用时，每个系统都对它做了非常多的配置和改进，在Linux中我们可以在系统文件中配置调度器的参数，例如队列级数、不同队列的RR切片粒度、优先级提升的时间间隔S等等

## Proper-Share策略

在上一节我们介绍了基于turnaround time和response time两个指标的MLFQ策略，现在我们引入一种新的体系，基于fair-share理念，也就是CPU时间分块分配的调度策略。这一类策略会给每个进程一个确定百分比的CPU时间，不已优化具体指标为目的，而是直接实现按需分配。我们将讨论三种基于这一理念的调度策略，来学习这种策略的基本思想和构建方法。

> 这里提了一种fairness的量化方法，大致就是执行时间相同的进程之间结束的时间越接近，则越fair

**lottery scheduling**

第一种是lottery scheduling，这一策略首先定义了票（tickets）作为分配CPU时间的标准。即给定每个进程一定份额的票，进程所持有的票数占全部票的比例就是该进程在这次时间片切换中获得运行时间的概率。workload如下图所示

<img src="http://1.14.100.228:8002/images/2022/02/07/20220207161152.png" style="zoom:67%;" />

> 简单解释一下上图，我们设定进程A的票数是75，进程B的票数是25，那么每次时间片切换中随机数为0-75则运行A，75-100则运行B

在lottery scheduling中，进程运行时间越长，获得响应比例的时间的准确性越强，且基于随机性的分配有三大好处

* 可靠（长时间下，如下图，时间越长公平性越高）
  * <img src="http://1.14.100.228:8002/images/2022/04/08/20220408110452.png" style="zoom:80%;" />
* 轻量（无需存储中间状态）
* 快速（就算一下概率）

lottery scheduling的基础理念比较简单，也有一些底层机制（ticket mechanisms）是一类的方法收到的基础，性能不错，但是最大的问题是：如何将票分给进程，因为和上面的MLFQ一样，系统没办法提前知道进程应当占用多少CPU资源。

**stride scheduling**

第二种是stride scheduling，这一策略首先定义每一个进程有一个stride，以此计算出pass，在一个时间片我们在当前运行的进程的counter上累加它的pass，每一次进程切换都选择counter最小的进程开始。workload如下图

<img src="http://1.14.100.228:8002/images/2022/02/07/20220207162608.png" style="zoom:50%;" />

基于stride scheduling，CPU时间被精准的分配到每一个进程上。看上去很好，而且它比lottery scheduling更加稳定，不需要长时间的运行也能保持公平性，但是它最大的问题是没有全局状态，stride是怎么初始化的？当有新的进程加入时，counter怎么算？这些问题都关系到进程产生后能否分配到和其它进程一样的CPU资源。

**Completely Fair Scheduler**

基于stride scheduling，科学家提出了The Linux Completely Fair Scheduler (CFS)。它的基础理念是为每一个进程分配各自不同的时间片，有些像加权版的RR策略，但是要复杂的多，具体的实现规则为：

定义**sched latency**，代表所有进程的时间片时间总和，再定义**min granularity**，代表进程的最小时间片，以确保不会在**上下文切换（context switch）**上开销太大。定义每个进程的**weight**，也叫nice level，用固定的表组成，有-20到19共40个权值，对应stride scheduling中的stride，这个值为正数表示优先级较低，为负数表示优先级较高。

<img src="http://1.14.100.228:8002/images/2022/02/07/20220207171130.png" style="zoom: 80%;" />

> 还记得吗，进程间切换需要将多个寄存器的值保存再替换，这样的一套操作就叫上下文切换

通过进程的weight，可以计算出本次sched latency中不同进程能够分配到的CPU时间

![](http://1.14.100.228:8002/images/2022/04/08/20220408141110.png)

stride scheduling中的counter在CFS中称为**vruntime**，在计算出每个进程的时间片后，选vruntime最小的进程开始，vruntime的大小变化和所占的CPU时间呈正相关，因此不会出现进程占用CPU过久的情况，这就是CFS的基本规则。

![](http://1.14.100.228:8002/images/2022/04/08/20220408141258.png)

此时进程表中每个进程都有对应的weight，为了帮助搜索众多进程中weight最小的进程，CFS采**用红黑树**存储进程信息，将O(n)的搜索时间复杂度降为O(logn)。

![](http://1.14.100.228:8002/images/2022/04/08/20220408141307.png)

当处理那些需要休眠的进程，也就是长时间IO的进程，CFS会将它们恢复时的vruntime设置为树中进程的最小值，这样能够解决休眠进程占用的问题，但是对于频繁休眠的进程，可能会造成其无法获得CPU时间。

通过巧妙的设计和高级数据结构的合理使用，CFS做到了较少的调度开销，提高了效率。此外CFS还有许多高级特性如提高**缓存性能的启发式方法**、处理多CPU和跨进程组调度等。

**小结**

通过前面一段的学习，我们初步了解了CPU的虚拟化的原理。首先，了解一系列重要的机制：trap和trap处理程序、计时器中断，以及操作系统和硬件在进程之间切换时如何保存和恢复状态。我们还了解到操作系统总是在确保一直负责机器的运行，通过运行受限保证恶意进程一直是收到限制的。我们还了解了调度器的概念，构建高性能的调度器是提升操作系统性能的关键，目前也存在许许多多的调度器，例如在Linux系统中CFS，BFS，O(1)等调度器一直都占有一定的部分。

## 地址空间

早期的操作系统进程数量很少，为内存管理设计的机制和策略比较少，之后多进程和分时系统的需求越来越高涨，如何在有限的内存上让几百上千的进程**互相不干扰**的运行，同时保持**高效**，成为了亟待解决的问题，解决这一问题的一系列技术就是内存的虚拟化技术。

内存虚拟化的第一个关键概念是**地址空间（address space）**，简单来说它就是内存这一概念在操作系统中的虚拟化。进程的地址空间（内存）中包含运行程序的所有内存状态，总结一下的话，就是代码、堆栈和堆（code、stack、heap）

以一个单线程的进程为例，操作系统为其分配的地址空间中包含了：

* 代码，也就是由代码编译而来形成的一条条指令；
* 堆栈，包含跟踪函数调用链的堆栈、参数、临时变量、返回值；
* 堆，由指令申请的空间，包含数据和主动分配的空间如malloc、new等

<img src="http://1.14.100.228:8002/images/2022/02/08/20220208194222.png" style="zoom:50%;" />

对于程序来说，这一块地址空间中的内存就是它可以调用的所有内存，从地址0开始，一直可以索引到最后。但实际上，真实的内存调用过程是：在一些重要硬件的帮助下，操作系统获取每个进程的内存引用（索引），并将它们**映射**到实际的物理地址上。

通过这项技术，操作系统给每一个用户进程都提供了一个大的（后面会说具体有多大）、稀疏的、私有的地址空间的**错觉**，这一技术是世界上所有现代计算机的基础。

为了达到现代操作系统的性能要求，虚拟化内存技术有三大目标

* 透明性：进程不应该知道内存是虚拟的，相反，要像真的有那么多内存一样让进程自由分配
* 高效率：虚拟化内存应该要快，不能让程序运行的更慢，应该要实现简单，不需要为支持虚拟化而使用太多内存
* 保护：进程之间、进程与操作系统之间的内存应当收到保护，不能相互覆盖

要实现这些目标，我们将会用到的方法有三个方面，必要的硬件支持、大量的低级机制、一些关键(高级)方法，这些都是之后需要了解的内容

> 在Linux中，我们可以使用free命令来查看内存的使用情况，free命令产生内存使用表，利用man(manual操作面板)命令来查看free的使用描述和表头含义

**实例**

因为这一技术过于重要，我们用一个例子来帮助理解

用过C语言的人都知道，我们经常能够看到一串串很长的十六进制码，那其实就是当前程序在运行时在它的地址空间中的一个**虚拟地址**，作为（非内核开发的）程序员，我们不管用任何语言能够看到的地址都是虚拟地址，只有操作系统才知道这些虚拟地址实际指向的物理地址

~~~c
#include <stdio.h>
#include <stdlib.h>
int main(int argc, char *argv[]) { 
    printf("location of code : %p\n", main);
    printf("location of heap : %p\n", malloc(100e6)); int x = 3;
    printf("location of stack: %p\n", &x); return x;
}
~~~

上面这个程序能够打印出main()例程的位置(代码所在的位置)，malloc()返回的堆分配值的值，以及一个整数在堆栈上的位置。打印结果如下

>location of code : 0x1095afe50 
>
>location of heap : 0x1096008c0
>
>location of stack: 0x7fff691aea64

可以看到代码首先在地址空间的上段，堆(heap)也是，而堆栈(stack)一直在这个巨大的地址空间（32位OS会给一个进程4GB的地址空间）

## 地址转换

之前学习过的limited direct execution可以简单理解为操作系统通过一系列机制限制用户进程进行任何“不正确”的操作，现在再提出一个对于内存的虚拟化有类似功能的机制：address translation。

通过address translation，操作系统可以将进程的每一个内存访问地址从地址空间，转换为实际存在的物理内存地址。

提供这样一种地址转换机制有两大意义，一是以此方式为进程提供一个可以随意分配的空间，方便程序的开发；二是为进程之间的运行和进程与操作系统之间的运行提供内存保护，任何一个进程都不能随意访问另一个进程的地址空间。

在实际讲解之前，我们先通过一个例子来建立一个简单的内存模型，下图是一个简单的C代码和它翻译出来的机器代码

![](http://1.14.100.228:8002/images/2022/04/12/20220412210314.png)

它的代码（指令）存储在它自身的地址空间中，而它的地址空间存储在物理内存空间中一块。

![](http://1.14.100.228:8002/images/2022/04/12/20220412210402.png)

一边理解这个模型，同时我们会以一种和CPU虚拟化类似的过程来设计出一个高效、可控、灵活的地址转换机制。

> 不管什么时候，高效和控制一直是操作系统主要的目标，在地址转换中，高效表示我们需要设计合适的算法、并且借助硬件的帮助。控制意味着系统不能允许不合理的内存访问。灵活表示在上面两个前提下，进程可以自由的访问它的地址空间中的任何内存。

类似的，为了简化模型，本次我们所学的机制都基于这几个关键的假设：

1.地址空间在物理内存上是连续的
2.进程地址空间不会很大
3.所有进程地址空间都一样大

一开始的地址转换非常简单（只用了几个寄存器），你应该也能猜到，就是存储一些变量。具体来说，就是两个寄存器：基寄存器和边界寄存器（原本叫**base-bounds**或者称为**dynamic-relocation**），是一种基于硬件的地址转换机制，每一个CPU都含有一对base register和bound register。其中base register负责将进程中的每一次内存访问进行偏移（相加）到实际的物理地址上，bound register负责查看进程的每一次内存访问是否在其所分配的地址空间内。

> 如果超出空间，则触发trap，由操作系统按照 exception程序来进行处理错误进程。
>
> 每一个CPU都有一个基寄存器，当CPU要切换进程，就会由OS加载它的基地址到寄存器上

![](http://1.14.100.228:8002/images/2022/04/12/20220412210515.png)

基于硬件的address translation十分高效稳定，但是无法利用到进程地址空间中栈和堆栈之间被分配但未使用的大量空间——这些空间也被称为internal fragmentation即内部碎片，这也是接下base-bounds要改良的方向

> 曾经出现过纯基于软件的地址转换，但是不仅低效，而且不能提供操作系统需要的保护。

至此，我们已经学习了不少在操作系统中由硬件支持的底层机制，我们可以将机器开机和简单进程运行时的各种过程抽象为下图

<img src="http://1.14.100.228:8002/images/2022/02/09/1.png" style="zoom: 50%;" />

包含了许多硬件机制：trap table、interrupt time、base-bound registers、switch context、kernel/user mode。还有许多操作系统的底层功能：各种硬件可触发的system call如time、exception等，存储进程状态和内存空间状态的process table、free list。

## 分段

上文提出的base-bound内存模型虽然达到了功能要求，但是地址空间中heap和stack中间大片的内存无法被灵活使用，我们需要一种更灵活的地址转移技术，也就是segmentation。

它的基本思想就是，在地址空间的每个逻辑段（代码区、堆栈区、堆区）上都有一对base-bound。目的是将每个段放在物理内存的不同部分，这样就不需要预留那么多空间给地址空间了。

![](http://1.14.100.228:8002/images/2022/02/10/20220210153743.png)

上图右半部分是segmentation的内存模型，segmentation将进程的code、stack、heap在物理内存上分开放置，分为三个不同的段，并给每一段都配置一对base-bound registers，当进程发出一个地址请求时，地址经由处理变为offset，也就是相对于其地址空间三个不同分段的的偏移量，再发送到bounds确认偏移量没有超出范围，之后与base相加/减得到在物理内存上的实际地址。

我们以一个实际的例子来看segmentation的工作流程，系统切换到某一个进程时，将其三个段的寄存器值填入，举例来说，可以是如下图所示，之后进程中的每一个内存访问都会通过这些寄存器分到不同的物理地址上。

![](http://1.14.100.228:8002/images/2022/04/13/20220413204625.png)

> segmentation fault就是机器对非法地址的访问引起的trap，这一种错误在分段这个思想出现后就一直保留至今

更加举例的来说，对于某一个地址空间的地址访问，我们可以将看作如下图所示，前两位是用于区分在作用在哪一个段上，后面是相对于寄存器值的偏移量。

![](http://1.14.100.228:8002/images/2022/04/13/20220413205444.png)

segmentation的大致过程如上，但是还有许多细节，硬件怎样确定发过来的偏移量是相对于那一段的？stack段地址空间向上填充需要相减（而不是相加）是怎样做的？这些由于篇幅掠过。

segmentation分段处理的方式还带来了另一个好处，不同进程的code段、stack段、heap段都可以实现一定程度的共享。在有序的前提下，不同进程共用一段代码，一个进程访问另一个进程的数据，这些操作可以大大增加的内存的利用率。具体的，可以共享的段会有**保护位（protection bit）**标识

![](http://1.14.100.228:8002/images/2022/04/13/20220413205759.png)

segmentation分段处理的方式也有一个难以解决的问题，不同进程的不同段在物理内存中稀疏的分布导致空余空间小而散，难以利用，这些空间被称为**external fragmentation外部碎片**。 转化前后直观来看可以像下面这样

<img src="http://1.14.100.228:8002/images/2022/02/10/20220210160303.png" style="zoom: 80%;" />

> 注意一般不会压到右边这样密集，因为这样的话已有进程几乎不能申请新的空间。

操作系统可以通过移动段位置来整理空间，但是这是一个trade-off的问题，空间紧凑则已有进程申请新空间则比较困难，空间稀疏则新进程申请空间十分麻烦。目前没有最优方案，一般可以通过一些智能算法或者定期压缩段来缓解这个问题。

segmentation解决了许多问题，利用上了潜在的巨大的内存空格键，实现了更深一步的虚拟化，它的实现也相对简单，硬件只需要根据接收的信息找到内存中各个分段的地址，无需关心分段的含义是什么。

但是它仍然不够灵活，不能支持足够稀疏的地址空间（外部碎片太多），比如说，进程堆空间必须是连续的，假如它很大的话，不能够放进那些松散的空余空间中，哪怕它们的总和远大于这个堆空间所占的体积。

## 空间管理

在进程中，具体的讲，是在地址空间的heap区，存在许多空闲内存，或者在操作系统上，进程内存空间之中也有许多未被分配的空闲内存。这两种空闲内存相对对象不同，但是都面临相同的问题，即怎样合理安排的内存空间的位置，才能让进程的内存申请变的更加高效。这引出了一类问题，即**空闲空间管理问题（free-space-management）**。

对于操作系统级的空间管理之前已经有所涉及，我们以更加简单的情况，即进程中heap区的空闲内存管理为模型，分析怎样管理内存。

首先是三个功能方面的底层机制，首先是splitting（分离）和coalescing（合并）机制，我们抽象进程heap区的空余空间都在free space table这个结构上：

* 当一片新内存被申请时，splitting机制让一块内存分离出和新内存相同大小的空间以供使用，而剩余空间依然在表里
* 当两片剩余空间地址上相邻时，coalescing机制让相邻空间合并成更大的一块。

> 很多时候我们会发现操作系统通过某些数据结构来跟踪系统状态，如何设计数据结构是系统能否高效执行的一个关键因素。

free space table的抽象模型可以看下图。

![](http://1.14.100.228:8002/images/2022/02/11/20220211204849.png)

> 当进程申请空间时，在free space table上有多块空闲内存可以分配，该将哪一块分配给进程，这是贯穿本节的最关键的问题，因为其对整个系统的内存分配均衡具有重要影响。但是关于这一点的讨论比较困难，因为我们当前的内存模型还不够灵活，现代空间调度算法大多基于我们之后会学到的更加灵活的模型，因此这里不讨论具体的调度算法。而是理解空余空间管理这一问题的性质和早期系统做过的尝试。

第二个机制是跟踪已分配空间的的大小，在使用free()函数时，我们并不需要指定需要释放的空间的大小，只需要把需要释放的变量地址指针传入即可。这是因为一个已分配空间的大小并不是保存在操作系统中，而是就在分配内存的头部，具体来说，free的机制如下图代码所示。

![](http://1.14.100.228:8002/images/2022/04/14/20220414132917.png)

第三个机制是将free space table嵌入到地址空间中，与记录已分配空间的的大小类似，将空余空间的大小保存在空余空间的头部

抽象的，我们可以认为heap中某一段空间的内存模型以及free space table在地址空间中嵌入的模型如下图所示

![](http://1.14.100.228:8002/images/2022/02/11/20220211205658.png)

其中free space table以链式形式存储，假如两片空间相邻，则会合并为一个空间。事实上，大部分进程一开始heap空间都是很小的，当需要更多空间时，可以通过system call如sbrk申请增加heap空间。

当一个变量/进程申请空间时，如何安排已有的空间来给出响应的空间是十分重要的，这一方面有许多策略，简单的有如Best Fit、First Fit、Next Fit等，而更复杂更高级的策略有Segregated Lists、Buddy Allocation等。事实上，这个领域到现在还是没有相当统一的优化方法，如果对空间调度器感兴趣的话，可以看一下glibc allocator这个调度器，了解一下现代调度器是怎样调度内存空间的。

**例子**

以一个简单的free space table为例，当一个大小为15的内存请求到达时，系统用不同的策略给予内存之后table的状态不同

![](http://1.14.100.228:8002/images/2022/04/14/20220414133340.png)

## 分页(一)—导引

segmentation方法是将空余空间分为variable-sized即可变大小的块，也由此带来了fragmentation的问题。我们介绍一种新的基于fixed-sized的方法，称为**page（分页）**，即基本思想就是将物理内存分为固定大小的page frames，每一个frame都可以对应一个virtual-memory page。page最大的优点就是灵活，系统能够高效的提供地址空间的抽象，而不用管进程怎么使用这些虚拟内存。page架构的模型如下图所示。

<img src="http://1.14.100.228:8002/images/2022/02/12/20220212210941.png" style="zoom:67%;" />

在这种架构下如何将进程的地址空间访问转化为物理内存的访问？操作系统为每一个进程都提供了一个数据结构称为page table，用来存储每一个进程由地址空间到物理地址的address translation。这种情况下，进程发出的每一个虚拟地址都不是单独的地址大小（偏移量），而是包含了至少两部分，即virtual page number (VPN)和offset，offset的概念上一节已经提到过了。我们举例一个大小为64 bytes的address space，每一个page是16 bytes，那么地址空间总共就有4个page，因此这个进程的虚拟地址总长是6 bit，其中2 bit是VPN，意思是属于哪一个page，例如01表示第一个page，4 bit是offset。

<img src="http://1.14.100.228:8002/images/2022/02/12/20220212210953.png"  />

操作系统和硬件一起将这个虚拟地址转化为物理地址，如上图所示，物理地址也是由一片片page组成的，由此我们得到VPN后就在page table中找这个属于这个进程的VPN对应的page是物理内存中的哪一个page，具体的说，地址空间01的page由地址转换器映射到PFN为111也就是物理地址的第8个page。

> 此处如果我们假设地址空间中的4个page都已经分配了，那么page table中就会存储有4个physical address

那么page table存储在哪里呢？对于一个32位、4KB per page的系统来说，光是VPN就有20位，一个X86系统的page table也有32位那么多，因此一个进程的page table就占用空间比较大，所有进程的page table加起来是相当大的。不可能存储在除存储硬件以外的硬件里，因此page table就存储在内存中，有可能在操作系统内存区以外的内存（老系统），也有可能在操作系统内存区中（现代系统）。

> 2的30次方是1G，因此32位的系统一个进程的地址空间就是4GB，一个64位的系统一个进程的地址空间则大到几乎是无限的

那么page table中存储着什么呢？以一个x86系统的page table为例，32位长度的page table占最多的是PFN，通过PFN可以直接映射到物理内存的某一个page上。此外还有一些用于其它功能的bit位，例如protection bit、present bit、dirty bit、reference bit、accessed bit、read/write bit等。

<img src="http://1.14.100.228:8002/images/2022/02/12/20220212211028.png" style="zoom:67%;" />

那么page table到底如何工作呢？一个虚拟地址的VPN被提取出来后，经由专门的page table base register得到属于这一VPN的page table的物理地址，硬件再由物理地址提取page table中的PFN等信息找到实际的物理地址，可以发现，这一过程比segmentation多了一步查找-转换。导致page在实际上是比较慢的，事实上，内存读取速度可能慢两倍甚至更多。要想实现可用的page策略，必须更加仔细的设计硬件和软件。

下图是page table工作流程的伪代码。比较详细的介绍了page table如何将虚拟地址转化为物理地址的整个过程。

<img src="http://1.14.100.228:8002/images/2022/02/12/20220212211111.png"  />

最后我们以一个C程序为例，看一看在page架构下，进程实际的内存访问情况。

<img src="http://1.14.100.228:8002/images/2022/02/12/20220212211140.png" style="zoom: 80%;" />

C程序很简单，循环赋值一个长度为1000的数组，右边是它的二进制码编译而来的机器语言。

<img src="http://1.14.100.228:8002/images/2022/02/12/20220212211206.png" style="zoom:80%;" />

实际的内存访问情况如图

## 分页(二)—快速转换

分页的基础方法对物理地址的查询依赖于page table，但是基于page table的查询需要两段步骤，因此速度很慢。这也就导致了分页方法带来了非常高的性能开销，为了解决这个问题，我们会增加一个内存缓冲区translation-lookaside buffer(TLB)，一基于硬件的虚拟地址-物理地址转换的缓存技术。通过TLB技术，大部分的内存访问申请都会经由缓存快速的定位，使page这一技术的可用性大大提升。

> 你可能在其它的地方见过缓存的技术，或许你会疑惑，内存的访问速度已经很快了，为什么还需要缓存。我们可以用下面这张图来直观的解释
>
> ![](http://1.14.100.228:8002/images/2022/04/17/20220417211134.png)
>
> 可以看到即使是L2缓存的读取速度也比内存读取速度块至少10倍，如果每一次内存请求都得访问内存至少两次的话，对于总体速度的影响是十分大的。

简单来讲的话，TLB就是一个离CPU十分近的存储结构，用来缓存以页表为单位的数据，一个典型的TLB有32、64、128个entry，entry大小就是页大小。在每次处理虚拟内存访问时，硬件会首先检查TLB中是否包含转换信息，如果没有，才会去查询物理内存。

TLB到底由什么组成呢？在TLB中，一个entry字段包含VPN、PFN以及其它的功能bit位。VPN和PFN的功能很明显就是不经由寄存器，直接由VPN映射PFN。我们由功能延申一下其它bit位的含义，首先是最重要的ASID位。当进行context switches时，不同进程的TLB可能会出现冲突，我们在entry字段中安放ASID字段作为进程的标识符。固定的，entry字段中还会有valid bit、protection bit、dirty bit等。

<img src="http://1.14.100.228:8002/images/2022/02/13/20220213191100.png" style="zoom:80%;" />

以简化版MIPS R4000系统中entry字段为例，由图可知，该系统中一个entry字段长64 bytes，包含除了我们上面说的部分以外，还有global bit、coherence bit等部分。

<img src="http://1.14.100.228:8002/images/2022/02/13/20220213191111.png" style="zoom:80%;" />

> 我们无法给每一个计算机硬件的单位内容都重新命名，因此我们用entry来描述一个结构中的基本单位，之后我们会大量的见到这种描述

具体的，我们以一个C语言程序为例子来解释一下TLB的工作原理，这个例子中page大小位16 bytes，因为一个整型变量的大小为4 bytes，40个bytes占三页，数组在地址空间中的占用情况如图所示。

<img src="http://1.14.100.228:8002/images/2022/02/13/20220213190939.png" style="zoom:67%;" />

我们假设一个TLB的大小是一页，每次内存访问到TLB中没有的页，就会将那一页存储到TLB中。

可以知道从程序开始到程序结束，TLB的使用情况为miss, hit, hit, miss, hit, hit, hit, miss, hit, hit。相当于70%的访问是被提前记录的，事实上，如果分页更大，变量空间占用越大，命中率还会继续提高到90%以上。

既然提到了命中率，那么没有命中的时候要怎样处理呢。这也是现代操作系统的一大分歧点，对于复杂指令集系统如CISC，例如intel x86系列，以硬件为基础来处理TLB miss的情况，也就是说，TLB miss并不会引发任何trap，硬件负责将新的TLB entry加入TLBs中，要做到这一点需要不少的硬件代价。下图是TLB参与整个内存访问的流程。

<img src="http://1.14.100.228:8002/images/2022/02/13/20220213191006.png" style="zoom: 80%;" />

对于简单指令集系统如RISC，例如MIPS R10k，则由操作系统来处理TLB miss，这样做有两个方面的优点，一是灵活，操作系统可以基于相同的逻辑，使用任意数据结构来构建page table和TLB，易于使用也易于更改；二是简单，硬件只需要在遇到TLB miss时引发一个trap，之后让操作系统处理即可。

<img src="http://1.14.100.228:8002/images/2022/02/13/20220213191018.png" style="zoom:80%;" />

早期RISC系统的芯片产生时引发了很多影响，因为明显RISC更快，但是经过这些年的演变，CISC逐渐吸收了很多RISC的特点，现在两者都可以达到很快的处理速度。

## 分页(三)—现代页表

如果简单的使用linear page table，也就是一个内存占用对应一个page table entry，那么每个进程的page table所占用的内存加起来会十分巨大。如果不解决这一问题page将难以实用。我们有许多不同的思路来解决这一问题。

> 一个 32位地址空间，页大小为4KB，page table entry大小为4 bytes的系统，一个进程最多有4MB的页表大小。100个进程就是400MB，这种大小的占用对于现代系统来说是不可接收的。

首先是直接增大page size。假如增大n倍的page size，那么page table的空间占用也会减少n倍，但是很明显这样会造成internal fragmentation问题，page size越大，page内部空间被浪费的概率就越高。不过由于这一方法的实现简单，现在multiple page size被应用于不少现代体系结构如MIPS、SPARC、x86-64等，但是主要是用于减少TLB miss的压力，而不是节省页表空间。

试想一下，我们其实没有必要给地址空间中未被实际使用的内存分配page table entry，如下图所示，valid为0的page table entry并不需要记录，为了做到这一点，我们需要更改page table的存储结构。

<img src="http://1.14.100.228:8002/images/2022/02/14/20220214163417.png" style="zoom: 80%;" />

因此另一种更加复杂的思路是混合page和segment，给进程中每一个segment一个page table，同样的，给每一个segment配一对base-bound。只不过这里的base用于记录page table的起始物理地址，bound用于记录page table的结束物理地址。通过这种方式page table只记录已经分配的部分，大大减少了page table的内存消耗，但是这样的话就又会出现segmentation的external fragmentation问题（治标不治本）。

page table只是数据结构，我们用很多方式去更改它以达到我们需要的目的，一种方式是multi-level page table多级页表。它的基本思想就是，如果一个page没有被具体分配，那么就不在page table里给它分配空间。听上去和hybrid有些像是么？但是我们不依靠segment，而是使用一种更灵活的实现方式，以两级页表为例，定义一种新的线性数据结构page directory。其中的内容称为page directory entry，包含两个基本信息，valid bit和PFN，如果valid bit为0，则不需要记录PFN。如果valid bit为1，则可直接通过PFN找到所属的page进行访问，抽象结构如图所示

<img src="http://1.14.100.228:8002/images/2022/02/14/20220214163458.png"  />

multi-level page table有两个好处，一是最为关键的，由于它只给地址空间中正在使用的部分分配页表空间，因此天然是紧凑的并且支持稀疏的地址空间。二是page directory中每一个entry都完整的在一个page中（如图中所示），这使得它本身的空间容易进行管理，操作系统可以简单的进行增删。

但是multi-level page table也有两个坏处，一是明显的，当出现TLB miss时，它所耗费的代价更大，因为需要两次访问进行新table的构建。二是增加了页表查找的复杂度，这一点和第一个缺点类似。

我们以一个实际的例子来理解multi-level page table的工作过程，一个地址空间大小为16KB，page size为64 bytes，那么virtual address为14位，其中8位是VPN，6位是offset。假如还是使用linear page table的话，page table有256个entry，每个entry占用4 bytes，那么这些entry一共占用16个pages，也就是说我们需要4个bit位的page directory index来进行page table的page索引，这4个位包含在VPN中，余下4个bit位用于在page中索引page table。如下图所示

<img src="http://1.14.100.228:8002/images/2022/02/14/20220214163524.png" style="zoom:67%;" />

索引到page directory后，根据page directory对page table进行映射，在本例中，原本要占用16个连续pages的page table只占用3个pages，如下图所示

<img src="http://1.14.100.228:8002/images/2022/02/14/20220214163536.png" style="zoom: 80%;" />

与TLB联系在一起，工作流程的伪代码如下

<img src="http://1.14.100.228:8002/images/2022/02/14/20220214163548.png" style="zoom:80%;" />

正如上面所说page table只是数据结构，还有其它更加节省空间的设计方式如inverted page tables等，但是更加小的空间占用无疑会带来更加大的索引开销，这依然是一个trade-off问题。并且内存问题并不是只有这一种解决思路，当内存紧张时，通过kernel virtual memory与硬盘进行swap也是一种page table内存问题的解决方法，不过这种内存极度紧张的情况并不多见。

## 交换空间(一)—交换机制

之前所讲的page策略一直都是基于一个基本的假设，那就是进程的地址空间都比较小，至多不会大于内存总大小。但是在现实中，进程随时有可能会申请非常大的地址空间，更不用说在现代操作系统中多进程同时进行是常态了。为了在这种情况下也能够达到内存的虚拟化（即对进程来说，想申请多少就申请多少，至于有没有那么多，让操作系统去想办法），swap space的概念被提出了。

抽象的说，swap space就是在disk space（磁盘空间）中保留的一片可以由操作系统以page形式读或写的区域，通过这一区域，操作系统能够将进程中不常用的部分交换到访问速度慢非常多的硬盘中，以此变相的扩充了内存空间。

交换空间相当于是内存空间“虚假”的扩大，它的大小决定了操作系统在给定时间内可以使用的最大内存页数，以四个进程为例，可以看到不同进程都各有一部分的空间在swap space中，处于blocked状态的进程则有可能全部在swap中，如Proc3。

<img src="http://1.14.100.228:8002/images/2022/02/15/20220215151518.png" style="zoom:67%;" />

> 在Windows中，如果内存空间不足，操作系统会在C盘创建虚拟内存文件用于存放溢出的内存数据，当我们经常加载大型数据集或者经常玩某一款大型游戏的时候能够看到。

为了嵌入这一新的机制，需要加入一个present bit抽象结构来表示page是否处于disk中，这里我们在page table entry的结构中加入一位，当访问到page table中present bit为0时，表示这一个page实际在disk中，触发page fault trap，由page fault handler来处理。

此时操作系统得到这个page的disk address，将其加载回内存中，再重新执行内存访问，之后的过程就和正常的TLB miss一样。需要注意的是，在加载回内存之前，操作系统需要判断内存是否足够，如果不够，则会触发replacement polices（PR），将一部分内存中的page换到swap space中，这也是我们第二部分要讨论的。

到目前为止，一个完整的基于硬件的page fault控制流如下图（仔细看，再捋一遍流程）。

> page fault并不是真的fault，它只是表示访问的虚拟空间不在内存中，不会引起进程中断之类的错误

<img src="http://1.14.100.228:8002/images/2022/02/15/20220215151552.png" style="zoom:67%;" />

在这种情况下，TLB miss有三种

1. 访问的是有效的内存，且在内存物理地址上（引发普通TLB miss）
2. 访问的是有效内存，且在磁盘swap space上（引发page fault）
3. 访问的是无效内存（直接引发trap，中断进程，或者报错）

replacement polices（RP）是判断哪些内存页能够交换到磁盘的方法，这对于swap space非常重要，因为硬盘访问的速度比内存慢足足1万到10万倍，如果RP经常判断失误，很可能造成显著的处理速度变慢。

操作系统用high watermark（HW）和low watermark（LW）来确保总是有一些空余内存，它们两个都是可以跳针的参数，表示内存额应该在什么时候进行swap，当可用内存低于LW，操作系统调用swap daemon也就是RP的执行线程来释放内存直到高于HW。

分组或集群是一类优化swap效率的方法，通过将多个page集群或分组，统一的swap入disk中能够显著的提高性能，但是这就并不在我们的讨论范围之内了。

## 交换空间(二)—交换策略

上一节我们介绍了swap scape这一基础概念（这一节的基础），操作系统通过swap space扩大内存，保留访问活跃的page，每一次都通过replacement policy来选择哪一个page来换出内存。我们只看page与进程的关系的话，某种意义上高速内存可以看作整个memory space的cache，衡量一个replacement policy好不好的指标可以是AMAT，具体公式如下

<img src="http://1.14.100.228:8002/images/2022/02/16/20220216191616.png" style="zoom: 80%;" />

其中Tm是访问内存的开销，Td是访问硬盘的开销，Pm是cache miss的概率，通过公式量化可以算出，由于内存和硬盘速度上的差异，进程访问内存的开销会随cache miss次数呈现巨大差异，举例来说，一个命中率为90%的系统可能比一个命中率为99%的系统内存访问速度慢100倍。事实上在高速硬盘出现前，内存和硬盘的差距实在是太大了，页面替换算法的重要性并没有那么高，因为频繁替换的成本太高，但是现在有SSD，所以替换算法的重要性也陡然增加。

遵循着由易到难的设计思路，replacement policy可以分为FIFO和Random、LRU以及LRU的变体。

在进程未来所有的内存访问我们都已知的情况下，我们可以让每一次replacement去除掉最久以后才访问的page，这是最优的情况。但是很明显这是不可能的，我们只能尝试去接近这个目标，FIFO和Random是简单的初步尝试，从名字就可知道，FIFO像队列一样处理page的替换顺序，先入的页在替换时也先出，Random则是随机选择替换page，模拟如下图所示

![](http://1.14.100.228:8002/images/2022/02/16/20220216182531.png)

FIFO实现简单，但是性能很差，Random同样实现简单，并且性能不稳定，但是在边界情况下也能发挥出性能。

> 边界情况简单来讲就是各种不符合常理的内存访问，很多replacement策略设计无法考虑到所有的边界情况，而random方法由于自身随机性能够自动处理这种情况，之后我们看到的random方法也都具有这种性质。

在计算机设计中有locality的概念，即某一个对象在被触发后，具有spatial locality和temporal locality的feature，假如P被访问，则P+1和P-1更有可能被访问，并且接下来P更有可能被再次访问。利用这种locality，Least-Recently-Used（LRU）方法被提出，它的基本思想就是，设当前page被访问的时间为T，那么里现在最久没被访问的page则最没有可能被访问，优先换出最远的page。

如何实现LRU，一种实现方法是假设page table或者物理空间中存储page中上一次被访问的时间，在出现需要换出page的时候搜索所有page中访问时间最远的那个page。

然而，对所有page进行搜索，尤其是现代系统page动辄上百万的数量，是极其耗费时间的。因此，近似LRU被提出了，加入了两个概念：**use bit**和**clock**。通过硬件支持，当进程每一次进行内存访问时，硬件将访问的page所属的use bit设为1，当需要换出page时，操作系统从clock hand指向的page开始遍历（或者其它任何方式，随机也可以），遇到1，则置为0，遇到0，则确认这一个就是要换出的page，这样近似的认为距离上一次访问最久的page就是可以换出的。

<img src="http://1.14.100.228:8002/images/2022/02/16/20220216185024.png" style="zoom: 80%;" />

基础的policies大概的思想就是这些，以下是它们的性能对比图，越接近黄线的最优越好，左上角的是当内存访问没有locality的一种边界情况，右下角的是一种只有Random有效的边界情况（其它的方法都失效了）

<img src="http://1.14.100.228:8002/images/2022/02/16/20220216185447.png" style="zoom:80%;" />

还有一些swap的优化方法，之前介绍page table中有一种dirty bit位，用于标记page是否进行了IO，如果没有进行IO，说明其数据相较于disk没有改动，如果要换出的话可以直接覆盖，如果进行了IO，那么就要将其写回disk中。有的policy对于没有进行IO的page更优先swap。还有page selection策略用于判断操作系统何时进行page swap，还有clustering and grouping策略用于增加swap的效率，这些policies没有replacement那么重要但是在现代操作系统中也是普遍存在的。

## 完整的虚拟系统

到目前为止我们已经学习了很多CPU虚拟化和内存虚拟化的底层机制和设计策略，现在我们以两个经典的操作系统：VAX/VMS和Linux，来看一下现代操作系统比较完整的虚拟化所用的技术都有哪些。

### VAX/VMS

VAX/VMS operating system是一款在七十年代末由Digital Equipment Corporation（DEC）开发出来的经典操作系统，其中有关虚拟化的技术很多是今天现代操作系统的来源，当时VAX系列系统需要在各种各样硬件条件的机器上运行，从大型机房到嵌入式设备，因此，VAX/VMS操作系统系统必须有支持其良好泛用性的机制和策略。

**基本信息**

VAX-11是一款 32-bit address space，512-bytes page size的系统，一条virtual address中包含23-bit VPN和9-bit offset，并且头两位的VPN用于标记page所属的是哪个segment。因此，这个系统基本内存策略是hybrid of paging and segmentation（记不住这是什么了？看看前面的文章）。

**VAX地址空间**

在VAX-11中系统地址空间分为上下两半部分，上半部分P用于用户进程使用，下半部分(S)用于内核进程使用。这两段分别有不同的page table，而用户地址空间上半部分又分为两个部分P0和P1，P0用于code和heap，P1用于stack。如下图所示。

<img src="http://1.14.100.228:8002/images/2022/02/17/20220217204544.png" style="zoom:67%;" />

> 图中 page0被标注为 invalid，我们规定 page 0是无效的页，任何更改 page 0的操作都会触发 trap。这对代码调试有很大的帮助。

VAX-11的page size十分的小，为了确保VAX-11不会因为page table占太多空间。VAX-11通过两种方法缓解page table占用问题。

第一个方法是两端page table，P0和P1两段分别有一个page table，因此stack和heap中间一大段没被使用的空间是不需要占用页表的。第二种方法是在内核虚拟空间中放置用户的page table，也就是在图中unused部分，这进一步的减少了内存占用。

在上下文切换的时候，操作系统更换P0和P1的寄存器，但是S的寄存器始终是固定的。将系统进程放进address space的好处有很多，例如它只需要负责本进程的系统调用即可，进行数据交互也无需额外的步骤，就像一个固定的程序库一样，虽然比较占空间，但是这种构造因其优越的性能得到现代操作系统的广泛采用。

**VAX替换策略**

在VAX系统的page table中，一个entry包含valid bit、protection field、dirty bit、一个保留给OS使用的5 bits字段以及PFN。并没有present bit，因为研究者发现present bit是可以被替代的。

VAX使用近似LRU策略作为替换策略，因为LRU策略并不是进程公平的，如果某一个进程一直大量申请空间，LRU会将其它进程的几乎所有page都swap出去。VAX使用不依赖present bit的segmented FIFO来进行page replacement。具体规则是：

每个进程都有它可以在内存中保存的最大页数，当页数超过限额时“先入”的页会被换出，这似乎与普通的FIFO一样，关键在于分段FIFO还引入了两个列表，分别时clean-page free list和dirty-page list。当有页面要换出时，会根据dirty bit放入两个列表中，当另一个进程需要空间时，先从clean-page free list中取页面进行覆盖，可以免去与disk进行交互。对于dirty-page list，因为磁盘在大的传输中表现更好，为了使交换I/O更有效率，VMS使用clustering策略将list中的page分组一起交换出去。

**其它优化**

VAX系统另外有两种“延迟“优化方法，也叫lazy optimal。它们分别是demand zeroing和copy-on-write。

demand zeroing是大多数现代操作系统都会有的一种lazy策略，当进程申请空间的时候，操作系统只在page table中放一个标记表示已经占用，当实际做IO的时候才触发trap让操作系统找到对应物理内存，清零并将其映射回地址空间。

copy-on-write也是几乎所有的现代操作系统都会有的一种lazy策略，当操作系统需要将一个页面从一个地址空间复制到另一个地址空间时，它可以将其映射到目标地址空间，并在两个地址空间中都标记为只读，当某一个进程对其进行写操作的时候，触发一个trap，操作系统将其内容真正复制到另一个物理地址上并映射回地址空间。

lazy optimal是一种十分有效且应用广泛的优化设计思想，其它的例子还有操作系统在接收到文件处理的指令后立即返回处理成功，但是实际在后台慢慢的处理文件。

### Linux

Linux的虚拟内存系统功能齐全、特性丰富且相当复杂，Linux的发展是由真正的工程师解决生产中遇到的实际问题而推动的，因此它的功能也在不断迭代。Linux和老系统有一些共同点，但是也有很多方面超越了传统的虚拟机系统（如VAX/VMS）。我们讨论最主要的英特尔x86的Linux上的虚拟内存系统。

同样的，Linux的地址空间有内核和用户两部分，同样内核部分在不同进程中是相同的。在经典的32位Linux中，地址空间的用户和内核部分的分割发生在地址0xC0000000处，或者是地址空间的四分之三处，而64位的Linux分割的点略有不同。

**两种内核虚拟地址**

从下图我们可以看出，在它的内核空间中有两种内核虚拟地址。

第一种被称为kernel logic address，大多数内核的数据结构都在这里，它与物理内存有直接的映射联系，例如内核逻辑地址0xC0000000转换为物理地址0x00000000，是有一一对应关系的。这么做有简化内核逻辑地址访问的作用，同时这使得在内核地址空间的这一部分分配的内存适合于需要连续的物理内存才能正常工作的操作，比如通过目录内存访问（DMA）进行的设备间的I/O传输。

另一种是kernel virtual address，这是一片是由操作系统主动申请，可以自由访问的空间，与内核逻辑内存不同，内核虚拟内存通常不是连续的，它的具体作用有很多，这里就不展开细讲了。

<img src="http://1.14.100.228:8002/images/2022/02/17/20220217221718.png" style="zoom:80%;" />

**页表结构**

x86的Linux有基于硬件的多级page table structure（不记得了？看看之前的文章），操作系统只需在其内存中设置映射，将一个privileged register指向页目录的开始，其余部分由硬件处理。具体的，目前64位系统使用四级页表。然而，虚拟地址空间的全部64位性质还没有被使用，而只是底部的48位，随着系统内存的增长，地址空间的更多部分将被启用，从而产生五级乃至六级的页表树结构，如下图所示

<img src="http://1.14.100.228:8002/images/2022/02/17/20220217221731.png" style="zoom:80%;" />

 **可变页大小**

Intel x86架构允许使用多种页面大小page，最近的设计在硬件上支持2MB甚至1GB的页面。Linux也使用这些huge page来提升TLB和其它相关的性能。因为如果page总是那么小，那么一个大内存的访问就会把TLB迅速填满，造成大量的TLB miss，最近的研究表明，一些应用程序花了足足10%的周期来处理TLB miss。

Linux对huge page的支持是以一种渐进的方式发生的，起初，Linux的开发者知道这种支持只对少数应用程序（eg.数据库）很重要，提供系统调用来申请huge page，由于对更好的TLB行为的需求在许多应用程序中更为普遍，Linux开发者增加了transparent huge page support。具体的说，操作系统系统会自动寻找机会来分配huge page提升TLB性能，进程不需要主动去调整页大小。

**页缓存**

为了提升访问硬盘的性能，大多数操作系统包括Linux都会建立cache subsystem，将活跃的数据保留在内存中，内存中保留的page来自三个方面：内存映射的文件、来自设备（例如硬盘）的文件数据、元数据（程序中总是被访问的数组变量）以及每个进程的heap和stack（有时被称为anonymous memory，因为它的下面没有命名的文件，而是交换空间）。这些entry被保存在一个page cache hash table中，当需要上述数据时，可以快速查找。

page cache跟踪这些entry是clean还是dirty。脏数据被后台线程定期写到支持存储（如果是文件数据，写到对应的文件中，如果是heap和stack则写到交换空间中），这种后台活动要么在某个时间段后进行，要么在有太多页面被认为是脏的情况下进行。这么做是为了帮助Linux判断哪些page是要从内存中swap出去的。

**替换策略**

Linux使用一种修改过的2Q replacement策略来进行page replacement。如果一个进程读取大量数据，但是却使用，那么LRU这时是没用的，2Q replacement创建两个列表分别称为active list活动列表和inactive list非活动列表，并将内存分给它们，当page第一次被访问时被放入非活动列表中，当被重新引用时，这个page被提升到活动列表中，当需要进行替换时，替换的候选页会从非活动列表中取出。Linux也会定期地将页面从活动列表的底部移到非活动列表中，使活动列表保持在总页面缓存大小的三分之二左右。这样做就可以处理LRU无法处理的情况。

硬盘与内存的映射出现的比Linux早一些年，在Linux中有一个系统调用mmap()能够指出内存映射在地址空间上的位置，事实上在Linux中每个普通的Linux进程都是内存映射的文件，我们调用pmap命令行工具能够查看搭配进程中文件的映射情况

<img src="http://1.14.100.228:8002/images/2022/02/17/20220217224926.png" style="zoom:67%;" />

从上图可以看到来自tcsh二进制的代码，以及来自libc、libcrypt、libtinfo的代码，还有来自动态链接器本身（ld.so）的代码都被映射到了地址空间。此外，还有两个匿名区域，即堆（第二个条目，标记为anon）和栈（标记为stack）。存映射的文件为操作系统构建地址空间提供了一种直接而有效的方法。

**系统安全**（选择性阅读）

以上都不是Linux和老操作系统的最大区别，它们之间的最大区别在于现代操作系统对安全的重视

buffer overflows是一种针对系统缓冲区溢出的攻击手段，这种漏洞的出现有时是因为开发者设计失误，当系统得到一个过长的输入，会发生缓冲区溢出，有人将溢出的恶意程序部分覆盖到目标的内存，成功注入到目标系统中，如果在与网络连接的用户程序上攻击成功，攻击者可以在被攻击的系统上运行任意的计算（比如挖矿程序）。

AMD在他们的x86版本中引入NX bit位来标记地址空间的某些区域不能够运行代码来防御这种攻击，但是攻击者发现即使注入的代码不能被攻击者明确添加，任意代码序列也能被恶意代码执行。这个想法在其最一般的形式下被称为面向返回的编程（ROP）。

为了防御ROC，Linux（和其他系统）增加了另一种机制，称为地址空间布局随机化（ASLR）。将代码、堆栈和堆放在虚拟地址空间的随机位置，从而使实现这类攻击所需的复杂代码序列变得相当有挑战性，在Linux中可以模拟这种随机放置，如右图所示，变量stack的地址每次都不一样。

<img src="http://1.14.100.228:8002/images/2022/02/17/20220217230433.png" style="zoom:67%;" />

ASLR对于用户级程序来说是一个非常有用的防御手段，因此它也被纳入了内核，其功能被称为内核地址空间布局随机化（KASLR）然而安全问题不止这些，在2018年，system相对安全的世界被两个新的相关攻击颠覆了。第一个叫做Meltdown，第二个叫做Spectre。它们大约在同一时间被四组不同的研究人员/工程师发现，并导致我们对计算机硬件和上述操作系统提供的基本保护提出深刻质疑。

这些攻击所利用的是现代CPU处理推测性行为的方式，CPU猜测哪些指令将在未来很快被执行，并提前开始执行它们。如果猜测是正确的，程序就会运行得更快，这样做能够显著增加系统运行速度，但问题是，它往往会在系统的各个部分留下其执行的痕迹，这种状态可以使内存的内容变得脆弱，甚至是我们认为受到MMU保护的内存。因此，增加内核保护的一个途径是将尽可能多的内核地址空间从每个用户进程中删除，因此，不再将内核的代码和数据结构映射到每个进程中，而是只保留最基本的内容，当切换到内核时，现在需要切换到内核页表，这种策略称为kernel table isolation。这样做提高了安全性，但是也降低了一部分性能，并且没有解决上面列出的所有的安全问题，而最简单的解决方案就是终止对推测性行为的优化，但这是不可能的，因为系统的运行速度会慢几千倍。

从上面的描述我们可以看出想要真正理解现代操作系统，就一定要理解操作系统的安全问题。







