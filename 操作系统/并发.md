## 抽象线程

在CPU与内存的虚拟化中，我们探讨的硬件环境一直是一样的普通单核处理器，但是当代计算机的CPU通常会有多个核心，给予处理器同时处理多个过程的能力。相应的，一种抽象——线程被提出来了。

一条线程指的是进程中一个单一顺序的控制流，一个进程中可以并发多个线程，线程之间有点类似于进程之间的关系，线程拥有独立program counter和register存储在thread control blocks(TCBs)中，通过context switch机制进行线程在单个processor上的转换，因此访问线程中的地址不需要通过PTL。

另外，线程在地址空间中的heap区以及code区是共享的，如右图所示。

<img src="http://1.14.100.228:8002/images/2022/02/25/20220225155346.png" style="zoom:67%;" />

引入线程这个抽象有明显的两大好处，一是并发处理，对一段数据线性的大批量处理可以交由多个线程分段共同完成，速度提升n倍，二是可以避免程序由IO引发的阻塞，当一个线程处理IO时，可以由另一个线程进行其它有意义的工作。

但是同时线程也带来了很多麻烦，由于线程的调度和进程基本上是一样的，所以假设只有一个核心，那么线程被创建之后的状态是不确定的，可能会立即执行，也可能会等待一段时间。这使得线程的执行顺序难以琢磨。由于共享内存，线程之间如果对一个公共变量同时进行操作，那么很可能会出现race condition（这里可以理解为某种数据访问冲突的情况）。

例如，对一个变量同时进行自增，结束时该变量结果并不是原来的两倍，并且它的结果是不确定的。这样需要保证在不同的线程上独立运行的程序我们称之为**critical section**，对于这样的程序我们希望它是**mutual exclusion**的，即同一时间只有一个线程在进行操作。

<img src="http://1.14.100.228:8002/images/2022/02/25/20220225164534.png" style="zoom:67%;" />

造成这一情况的根本原因是未对这种新的抽象设计新的调度控制方法，因为普通的CPU指令所对应的操作是**原子操作**，例如上图中汇编指令mov、add。一个个的原子操作在按顺序执行时可能在关键的地方遇到**time interrupt**，尚未更改的数据又被另一个线程读取，造成数据紊乱。

为了解决这一问题，我们可以将当前的原子操作集合起来包装为**synchronization primitives**，让其也拥有原子操作“all or nothing”的特征。当然，要实现这一目标，我们要想出许多独创性的方法，必然需要硬件的支持和软件的构建。

> 这一节有几个之前没见过的专业词汇，有critical section、mutual exclusion等，这里先暂时记住，之后随着学习过程会加深理解的。

当然，线程带来的问题不止这些，sleeping/waking interaction的实现也需要新的机制，这些都是后话了。

## 锁

上面提到我们需要一种将critical section组合成一个原子操作的方法，这种方法就是Lock(锁)，其基本思想就是维护一个各线程之间共享的**lock variable**，当lock variable为available (or unlocked or free)时critical section部分内只有一个线程在执行代码，其它线程的在lock()处因为lock variable是acquired (or locked or held)的状态，所以无法进入critical section部分。

> 线程虽然主要收到操作系统调度，但是通过这种方式，程序员能够获得部分调度的控制权，锁有助于将传统操作系统调度中的混乱转变为更可控的活动，本质上是将CPU调度无法覆盖到的方面交给程序员来管理。

锁的一种实例是在POSIX库中包含的互斥锁(**mutex lock**)，其逻辑可包装成下图右侧所示，图中变量lock就是lock variable，只有lock未被占用时，才允许线程进入critical section（这里是变量balance自增）。

![](http://1.14.100.228:8002/images/2022/02/27/20220227204501.png)

系统如何构建锁？在讨论锁的构建原理之前，首先要对锁的性质进行标准制定，根据锁的实际应用需求，可以按照重要性提出锁应当满足以下要求

* 能否提供mutual exclusion，即最基本的只让一个线程进入critical section。
* 能否让线程公平竞争，当有线程运行时，其它线程能否公平的得到CPU资源
* 能否在不同情况下让锁带来的性能开销最低

最初的lock方法依循最简单的思路，即提供一个系统调用，直接暂时停止中断器工作，直到另一个系统调用恢复中断器工作，这种方法的唯一好处就是实现简单。另外就是一堆缺点

* 程序权限过大，非常不安全，如果程序一直调用停止中断器，相当于接管了系统
* 在多核处理器上不通用
* 造成系统调度紊乱，中断器是操作系统能够介入问题程序的物理保障，会造成调度困难
* 性能太差，这样做开销太大

由于这些缺点，所以现在只有在一些小型机器还能找到这种提供锁的方法

既然直接停止不行，我们就想到lock variable本身，即使用一个flag来表示是否有进程占用锁，这就是自旋锁的最基础原理，似乎解决了问题。但这种方法太过原始，有两大问题，一是准确性：假如线程1在结束之前就遇到计时中断，而切换到另一个线程2，此时线程2依然可以进入critical section。基础过程伪代码和准确性问题解释如下图所示（因为篇幅原因这里不能讲太细，可以结合下图思考理解）。

![](http://1.14.100.228:8002/images/2022/02/27/20220227210610.png)

二是性能问题，上图右边在切换回线程1的时候，线程1是无法再次进入critical section的（假如需要再次进入）。那么这一个time slice相当于进程1空转，CPU资源被浪费了。

**Test-And-Set**

这时我们可以寻求一些硬件支持，在60年代的Burroughs B5000系统中，设计师提出了一种功能更强大的指令：Test-And-Set。它的功能如下图中C代码所示，返回old_ptr所指的数同时更改其为new。这个操作序列是以原子的方式执行的。它被称为Test-And-Set的原因是，你能够“test”旧的值同时“set”一个新值；事实证明，这条更强大的指令足以构建一个简单的自旋锁。下面代码能够用于描述它的作用原理。

![](http://1.14.100.228:8002/images/2022/02/27/20220227214131.png)

**注**：不同硬件架构中Test-And-Set的名称不同，例如SPARC中叫 load/store unsigned byte，x86中叫atomic exchange。

我们如何评价这种简单的自旋锁呢，首先是准确性，它毫无疑问是准确的，只有一个线程能够进入critical section。

然后是公平性，它并不能保证所有等待的线程都能够有机会进入critical section，因此它是不公平的。

之后是性能，这里我们要分情况看待，假如在单核CPU上，这种锁是性能很差的，原因和上面一样，当有一个线程运行时，其它所有线程都在空转浪费CPU资源。但是在多核CPU上，这种方法性能还行，其它线程可以到其它核去空转，虽然也是浪费，至少程序执行速度不会减慢多少。

**Compare-And-Swap**

另一种硬件支持是Compare-And-Swap，也叫CAS算法，它的功能如下图中C代码所示，其基本思想是通过比较和交换来测试ptr指定地址处的值是否等于预期值；如果是，用新值更新PTR指向的内存位置。如果没有，什么也不做。

![](http://1.14.100.228:8002/images/2022/02/27/20220227214623.png)

可以看出来，compare-and-swap是一种比test-and-set功能更强大的指令，当我们要研究**无锁同步**之类的主题时，我们将使用这种功能。但是如果我们只是用它构建一个简单的旋转锁，它的行为与我们上面分析的旋转锁相同。

**Load-Linked and Store-Conditional**

还有另一种硬件支持是Load-Linked and Store-Conditional，分别有Load-Linked和Store-Conditional两个指令，其中load-linked的操作很像一个典型的load指令，只是从内存中获取一个值并将其放入寄存器中，store-conditional定义只有在LoadLinked读取ptr地址上的数据之前ptr没有更新过才表示成功。如果成功，storeconditional返回1，并将ptr的值更新为value；如果失败，则不会更新PTR上的值，并返回0。通过Load-Linked和Store-Conditional组合来构建锁，具体过程如下图所示

![](http://1.14.100.228:8002/images/2022/02/27/20220227221702.png)

Load-Linked and Store-Conditional在MIPS和ARM架构中比较常见

**Fetch-And-Add**

最后一种硬件支持是Fetch-And-Add，基于这一支持构建的票锁有一个非常易懂的例子，假设饭店只有一个位子

1. 初始时位子是空的，叫号0
2. 第一位顾客取号，取号0
3. 匹配号成功，成功就餐
4. 第二位顾客取号，取号1，当前叫号为0，不匹配，自旋
5. 第一位顾客用餐结束，工作人员叫号1
6. 第二位顾客取号1与叫号1匹配，进入就餐。

<img src="http://1.14.100.228:8002/images/2022/02/27/20220227222804.png" style="zoom: 80%;" />

通过Fetch-And-Add这种方式构建的锁保证了公平性，因为每一个线程都一定会在之后得到进入critical section的机会。缺点是拓展性差，如果等待者很多，在释放锁时，递增（餐厅服务人员叫号：请100号客人用餐）锁号时，会将其他所有等待线程中的（叫号）锁号缓存cacheline置为无效invalid。会通过内存主线重新加载新的值到缓存cacheline。这样会造成“拥堵”。因为叫号更新了，我手里的号码需要跟最新的叫号号码比较是否相等，如果相等说明到我用餐了。

**提升性能**

上面我们提到多个线程在自旋锁中会有很严重的CPU资源浪费情况，怎么办呢？我们假设有一个系统调用yield()，一旦线程遇到lock被占用就调用yield()，直接从running状态调换成ready状态。这样减少了很多线程空转，但是依然每次都要让每一个线程执行yield()，这依然相当浪费时间

于是我们的思路转换为，不应该让每一个线程每次都去试探是否有锁，在当前持有者释放锁后，我们必须显式地对接下来哪个线程获得锁施加一些控制。我们寻求操作系统的支持，帮助我们调整线程的状态，再创建一个队列来跟踪哪些线程正在等待获取锁。

以Solaris系统为例，系统调用park()将调用线程置于睡眠状态，而unpark(threaddid)唤醒由threaddid指定的特定线程。具体过程如下图所示

<img src="http://1.14.100.228:8002/images/2022/02/27/20220227230107.png" style="zoom:80%;" />

这种方法并不能够完全避免线程自旋，但是已经优化到足够的程度了

其它系统也有类似的调用，如Linux中的futex，类似Solaris，但是提供了更多的内核内功能。具体来说，每个futex都有一个特定的物理内存位置，以及一个每个futex的内核队列。调用者可以根据需要使用futex调用来调整线程Sleeping还是Wake，这两种futex调用分别是futex wait(address, expected)和futex wake(address)

最后，Linux的方法有一种已经断断续续使用了多年的老方法的风格，至少可以追溯到20世纪60年代早期的Dahm Locks，现在被称为两阶段锁。两阶段锁意识到旋转可能很有用，特别是当锁即将被释放时。所以在第一阶段，锁会旋转一段时间，希望它能获得锁。

但是，如果在第一个旋转阶段没有获得锁，则进入第二个阶段，在这个阶段调用者被置于睡眠状态，只有在锁稍后被释放时才被唤醒。上面的Linux锁就是这种锁的一种形式，但它只旋转一次;在使用futex支持睡眠之前，这种方法的泛化可以在一个固定的时间内循环。

## 基于锁的并发数据结构

在了解锁的概念后，我们将目光放在程序访问的核心——数据结构上。即我们要怎样利用锁构建线程安全的数据结构呢？这是一个非常深的领域，这一节我们只探讨几个经典的例子。

第一个是并发计数器，计数器就是一个可以进行自加自减的数据结构，对于计数器的并发控制我们已经很熟悉了，可以简单构建出一种并发计数器，逻辑如下图代码所示。

<img src="http://1.14.100.228:8002/images/2022/02/28/20220228183843.png" style="zoom:80%;" />

可以看到右边的代码在数据变化的语句周围都上了锁，保证了数据的并发安全。这种计数器设计简单，但是完全不是scalable（可拓展的），性能有很大问题。

我们知道每个CPU核心都有一个计数器，假设在四核Intel 2.7Ghz i5 CPU上运行四个线程，每个线程自加一百万次，结果我们会发现线程之间有很严重的延迟问题，一个线程自增只需0.3s，两个线程自增总耗时就需要4s以上，正常来说我们希望两个线程是并行的，一个线程应当和两个线程差不多，但事实是，线程越多，耗时指数增加，这就是为什么说这样实现的计数器**不可扩展**的含义。

该怎么解决这个问题呢，我们知道理想状况下多个线程多个核的运行时间要和一个线程一个核的运行时间接近。因此有人设计出一种近似计数器，它的工作原理是通过多个本地物理计数器表示单个逻辑计数器，每个CPU核一个计数器，以及一个全局计数器。其体来说，在一台有四个cpu的机器上，有四个cpu。前7个单位时间内各个计数器的状态如图。

<img src="http://1.14.100.228:8002/images/2022/02/28/20220228184001.png" style="zoom:80%;" />

设置一个阈值，当线程自增（或自减）达到阈值时统计到全局变量G中，不同的核心用不同的锁。为什么说是这是近似的方法呢，假如进程结束时，

同样的我们量化这种方法的效率，可以看到，通过避免所有线程共享同一个锁，程序执行时间有了质的提升，更关键的，这种数据结构变为可拓展了。

<img src="http://1.14.100.228:8002/images/2022/02/28/20220228184045.png" style="zoom:80%;" />

> 在这里我们通过增加可操作的锁的数量提供了数据结构的并发性，但是这并不是通用的方法，大多数时候减少调用锁例程才是优化性能的方向，下面会提到。

第二个是并发链表，首先遵循简单的思路，即直接在数据操作的部分加上锁，具体逻辑如下图代码所示，在这里有一些小细节，插入和查询部分的代码中锁的放置需要遵循一个准则，具体的在原书中进行查看。注意这种实现的链表并不是可伸缩化的，一种伸缩化的思路是在链表的每一个元素上都上锁，但这很可能造成调用锁例程过多，具体性能要根据情况进行评测。

第三个是并发队列，我们知道，总是有一种标准的方法来创建并发数据结构：添加一个大锁，将其嵌套在操作之外，但队列的实现略有不同，我们定义两个锁，一个用于队列的头，一个用于队列的尾。这两个锁的目标是支持入队列和出队列操作的并发性，具体逻辑可以看下图代码。

队列通常用于多线程应用程序。然而，这里使用的队列类型(仅带锁)通常不能完全满足这类程序的需要。一个更完整的并发队列实现是有界队列，它允许线程在队列为空或过满时进入等待状态，这里就不展开讲了。

下图是**并发链表**和**并发队列**的简易构建代码：

<img src="http://1.14.100.228:8002/images/2022/02/28/20220228184210.png"  />

最后一个是并发哈希表，我们基于之前构建的并发链表来构建并发哈希表，下图显示了并发更新下哈希表的性能。为了便于比较，还展示了一个链表(只有一个锁)的性能。从图中可以看出，这个简单的并发哈希表扩展性非常好；相比之下，链表则比较差。

<img src="http://1.14.100.228:8002/images/2022/02/28/20220228184256.png" style="zoom:80%;" />

因为并发数据结构的构建实际上非常复杂，并且在现代系统中也非常重要，这一研究领域的详情不可能在这么短的篇幅下展示出来，因此本节只是稍微讨论了并发数据结构的部分思想，详细的还是要自己学习。

## 条件变量

之前我们解释了锁和基于的锁的并发数据结构，已经可以构建一个小型的并发程序。但是我们只注意于对线程操作的数据的保护，而忽视了线程与线程之间的关系处理。事实上，有很多情况是线程需要确认条件允许，再进行下一步的操作，这种条件在线程之间如何共享，如何管理是我们所需要关心的。举例来说，当父线程运行到某个特定节点时，它要确认所有子线程已经结束再进行下一步的操作，这时候可以调用join()。一种用于线程同步的技术。

<img src="http://1.14.100.228:8002/images/2022/03/03/20220303170510.png"  />

我们可以创建一个全局变量，用于标识父进程是否能够继续执行，当条件不允许时，父进程一直等待并检查条件变量。这样功能完成了，但是明显是低效的，因为父进程一直在浪费CPU资源。因此，我们需要一种能够让线程进入睡眠状态，直到条件允许的时候再唤醒的方法。

为了构建这么一个系统，前人提出了**条件变量(Condition Variable)**这一概念，具体的说，条件变量是一个显式的队列，当某些执行状态(即某些条件)不符合时，线程可以将自己放在这个队列中；当其他线程改变状态时，可以唤醒一个(或多个)正在等待的线程，使它们继续执行。所以这里条件变量并不是某一个数值，而是一种数据结构。

条件变量有两个操作，wait()和signal()。当线程希望自己进入睡眠状态时，就会调用wait()；当一个线程执行完了某些操作，因此想要唤醒一个正在等待中的线程时，就会执行signal()。当然，为了确保同步性，这两个调用都会用到锁。线程在调用wait()之后，将锁作为参数输入，线程进入睡眠状态并释放锁。在调用signal后，某一个符合条件的线程被唤醒并立即得到锁。下图是一个双线程的示例

<img src="http://1.14.100.228:8002/images/2022/03/03/20220303172730.png" style="zoom:80%;" />

在上面的例子中，变量done以及锁变量m都是必须的，因为这两个相互配合，使得父线程和子线程的操作有原子性，而不是在某个时间点卡死。用while不用if是因为这样程序才能够能够处理多个子线程或者父线程。

条件变量的原理我们知道了，但是似乎还不够完善。我们再看条件变量在Producer/Consumer问题（生产者/消费者问题）上发挥的作用。Producers指那些生成数据并且放置在**有界缓冲区(Bounded Buffer)**的线程，Consumers指那些从有界缓冲区取出数据并使用的线程。例如，在一个多线程的web服务器中，Producers将HTTP请求放入一个工作队列(即有界缓冲区)；Consumers将请求从队列中取出并处理它们。因为有界缓冲区是共享资源，我们当然需要对它进行同步访问，以免出现race condition。

我们定义一个简单的有界缓冲区，即一个只存一个数字的内存位，用get()和put()调用来表示对这个内存位的拿和放的操作。结合上面的知识来设计并发程序对这个内存位进行读写。

![](http://1.14.100.228:8002/images/2022/03/03/20220303190631.png)

上图左边是最初的一版设计，而右边第二、三版对应解决的问题是

* 同类线程的竞争问题
* 线程的有向选择问题

![](http://1.14.100.228:8002/images/2022/03/03/20220303190836.png)

经过设计，现在的程序能够在多个生产者/消费者线程同时执行的情况下保持稳定读写。如果再将有界缓冲区扩展为多个位置，则可模拟大多数Producer/Consumer问题下的通用解决方案，代码如下

<img src="http://1.14.100.228:8002/images/2022/03/03/20220303191128.png" style="zoom:80%;" />

条件变量不只能用来解决Producer/Consumer问题，具体的说，假如有一段在多线程内存分配库中的程序，功能为分配与释放内存。假设进行Free的线程为T1，进行alloc的线程为T2和T3。对于T1来说，释放空间后就要唤醒分配空间的线程。这时问题是：该唤醒哪一个线程，这种情况被称为**covering condition**。

解决方案很简单，将代码中的signal()调用替换为broadcast()，这样可以唤醒所有等待的线程，这样的话我们能保证任何应该被唤醒的线程都是被唤醒的。当然，这样做的缺点可能是对性能的负面影响，因为我们可能会不必要地唤醒许多其他本应(还)处于等待状态的线程。这些线程将简单地唤醒，重新检查条件，然后立即回到睡眠状态。

<img src="http://1.14.100.228:8002/images/2022/03/03/20220303194509.png" style="zoom:80%;" />

covering condition问题提醒我们，对条件变量的操作是要根据实际情况来调整的，不是盲目的使用signal和wait。

## 信号量

例一：

~~~c
sem_t empty;
sem_t apple;
sem_t banana;
sem_t mutex;
sem_init(&empty, 0, 1);
sem_init(&apple, 0, 1);
sem_init(&banana, 0, 1);
sem_init(&mutex, 0, 1);

# producer_father
void *producer_father(void *arg){
    p(empty);
    p(mutex);
    put_apple(1);
    v(mutex);
    v(apple);
}

# producer_mother
void *producer_father(void *arg){
    p(empty);
    p(mutex);
    put_banana(1);
    v(mutex);
    v(banana);
}

# consumer_son
void *consumer_son(void *arg){
    p(banana);
    p(mutex);
    get_banana();
    v(mutex);
    v(empty);
}

# consumer_daughter
void *consumer_daughter(void *arg){
    p(apple);
    p(mutex);
    get_apple();
    v(mutex);
    v(empty);
}
~~~

我们已经学习了锁和条件变量的含义和使用方法，有人可能发现这两个概念的功能虽然有很大区别，但是形式上有些相似。这是因为锁和条件变量都是**信号量(Semaphores)**的高层抽象。所谓信号量就是一个带有**数值**的对象，是一种专门用于提供不同**进程间或线程间**同步手段的原语（primitive），由内核来维护，独立于进程。因此可以通过它来进行同步。信号量的初始化非常重要，对应不同情况下信号量的功能。信号量的初始化和两个例程如下图所示。

<img src="http://1.14.100.228:8002/images/2022/03/05/20220305122152.png"  />

sem_init()的第二个参数一般都为0，这表示信号量在当前进程中的各个线程之间是共享的。第三个参数表示要将s赋为何值。wait()和post()函数的功能如内部描述的那样。这里有两个注意，一、这两个例程是原子操作；二、s为负数时，它的数值代表正在等待的线程，一般来说这是用户看不到的值。

当信号量被初始化为1时，代表二进制信号量，通过调用信号量的两个例程，这个时候信号量发挥出锁的功能。下图是一个信号量作为锁的功能示例。

<img src="http://1.14.100.228:8002/images/2022/03/05/20220305125926.png"  />

我们经常发现一个线程在等待一些事情的发生，另一个线程让一些事情发生，然后发出它已经发生的信号，从而唤醒等待的线程。当信号量被初始化为0时，通过调用信号量的两个例程，这个时候信号量发挥出条件变量的功能。下图是一个信号量作为条件变量的功能示例。

<img src="http://1.14.100.228:8002/images/2022/03/05/20220305131008.png"  />

既然信号量还有条件变量的功能，我们同样探究信号量在Producer/Consumer问题上的应用，同样的，这时候要设置两套信号量，一套初始化为0，表示正在等待的consumer线程，另一套初始化为缓冲区的大小，表示当前缓冲区的空位有多少。信号量架构代码和并发操作逻辑如下。

<img src="http://1.14.100.228:8002/images/2022/03/05/20220305132822.png"  />

注意如果锁和条件变量构建不当的话可能会有死锁问题。

再看另一个可以利用信号量来解决的问题，Reader-Writer Locks，对于一些数据结构可能需要不同种类的锁。有时甚至需要我们自己去实现一种锁。例如在一个列表的操作中，插入和查询是不能同时进行的，我们用信号量来实现多线程查询和插入操作隔断。具体实现方法如下图代码片段所示。

<img src="http://1.14.100.228:8002/images/2022/03/05/20220305151347.png" style="zoom:80%;" />

这种方法有效，但也有一些缺点，特别是在公平方面。例如，读取线程很容易让写入线程starving。因此我们要想办法让写入线程等待时限制读取线程的增加。

还有一些其它问题需要信息量来参与解决。例如哲学家问题，五个哲学家围在餐桌旁，只有五个刀叉，每个哲学家要拿到两个刀叉才能吃饭，明显这里有吃饭时的死锁问题。这个问题虽然没什么实际意义，但是很经典。另一个问题是线程溢出，假如线程非常多，例如几百上千个。就有可能造成系统崩溃，因此我们要设置一个阈值让线程数量维持在一个差不多的位置。这其中的取舍又是很多内容，例如哪些线程是应该留着的？当新线程产生时，是直接让其中断还是取代其它线程？

因为信号量和条件变量、锁的概念是相通的，所以我们可以用条件变量、锁来实现我们自己的信号量，但是基本没人会这么干，因为信号量的优点就是简单通用，一些程序员甚至只使用信号量，避免使用锁和条件变量，因为信号量的简单性和实用性。

**小结**

[线程同步：互斥锁，条件变量，信号量 - Loull - 博客园 (cnblogs.com)](https://www.cnblogs.com/549294286/p/3687678.html)

我们学习了锁、条件变量、信号量，有人可能会对这三个类似的概率有些混乱，可以看上面的链接文章，因为内容较多，这里就不再赘述。

## 常见并发问题

我们已经学习了并发问题的解决工具，锁、条件变量、信号量。但是如果对并发问题没有一个准确认知的话是无法编写出合格的并发程序的。尤其是将一些常见的Bug记在脑子里是编写合理的并发程序的前提。

如果从实际应用中总结并发程序的bug，可以发现在MySQL、Apache、Mozilla、OpenOffice这样的成熟的软件里面也会有很多并发Bug，如果将并发Bug分为非死锁和死锁两种，可以得到如下的图片。

<img src="http://1.14.100.228:8002/images/2022/03/07/20220307232347.png" style="zoom:80%;" />

对于非死锁问题，我们使用研究中的示例来推动我们的讨论。而对于死锁问题，前人已经探索了许多方法去预防、避免和处理死锁。

非死锁问题可以分为两种，原子性冲突和顺序冲突。原子性冲突就是我们常见的中断引发的critical section问题。 如下图所示，只要在冲突部分加上锁就可以解决这个问题。

![](http://1.14.100.228:8002/images/2022/03/07/20220308092223.png)

顺序冲突则是由于子线程比父线程执行更快造成的代码顺序问题，如下图所示，应该用锁和条件变量来规定线程之间的执行顺序，这样就可以解决问题。

![](http://1.14.100.228:8002/images/2022/03/07/20220308092816.png)

死锁问题是在许多具有**复杂锁定协议**的并发系统中出现的一个经典问题，死锁发生的概率比非死锁小很多，但是一旦发生就是系统崩溃级别的问题，因此对死锁的处理一直以来都有很多人研究。我们首先弄明白为什么死锁会发生，一个简单的死锁如下图所示，线程1和2互相调用锁，又互相持有锁不放，所以发生了死锁。

![](http://1.14.100.228:8002/images/2022/03/07/20220308093522.png)

那么如果线程1和2都以相同的顺序获取锁，那么死锁就不会发生了。原理很简单，但是在实际的软件开发中，我们所调用的各种封装函数和包大部分都是对我们透明的，因此我们无法确切了解程序中各种锁的调用情况。例如，假如有两个依赖互相调用，则很有可能出现死锁，这称为**循环依赖（circular dependencies）**问题，`例如在python中包不能在全局相互调用`。封装好的接口隐蔽性强，所以不能和我们自己定义的锁很好的配合，例如在Java Vector类中

~~~java
Vector v1, v2;
v1.AddAll(v2);   //这种相互的资源调用有可能出现(循环)死锁
v2.AddAll(v1);
~~~

对于死锁的原因严谨定义可以归结为如下四点：

* Mutual exclusion：线程要求独占地控制它们所需要的资源(例如，一个线程抓取一个锁)。
* Hold-and-wait：线程持有分配给它们的资源(例如，它们已经获得的锁)，同时等待额外的资源(例如，它们希望获得的锁)。
* No preemption：资源(例如，锁)不能从持有它们的线程中强制移除。
* Circular wait：存在一个循环的线程链，每个线程持有一个或多个资源(例如，锁)，这些资源正在被链中的下一个线程请求。

如果以上四个条件中任意一个不满足则不会发生死锁，因此，当我们遇到死锁问题时，首先可以从上面四个方向去思考解决方案。

第一个是Circular wait，这也是我们最有可能遇到的问题，预防循环的线程链产生的最直接方法是定义锁获取的总顺序，如下图所示，定义锁的物理地址作为锁的获取顺序，假如m1的物理地址高于m2，则m1总是优先于m2被获得，这样就可以防止循环链。

~~~c
if (m1 > m2) { // grab in high-to-low address order 
    pthread_mutex_lock(m1); 
    pthread_mutex_lock(m2);
} else { 
    pthread_mutex_lock(m2); 
    pthread_mutex_lock(m1);
}
~~~

这种方法全部顺序和部分顺序都需要仔细设计锁策略，并且必须非常小心地构造。因此并不是很高效，并且有时实施起来很复杂。

第二个是Hold-and-wait，我们可以对程序中所有锁的获取加上一个全局锁，这样保证了在获取锁的过程中不会发生不适时的线程切换，因此可以再次避免死锁。

~~~c
pthread_mutex_lock(prevention); // begin acquisition 
pthread_mutex_lock(L1); 
pthread_mutex_lock(L2);
...
pthread_mutex_unlock(prevention); // end
~~~

和前面一样，这种方法要求我们确切地知道哪些锁必须被持有，并提前获取它们，因此实际实施有困难。这种技术还可能降低并发性，因为所有锁都必须在早期(同时)获得，而不是在真正需要时获得。

第三个是No Preemption，锁在被调用时是无法被其它线程再次调用的，这是锁的基本性质，但是我们可以更改调用锁的方式，例如构建可释放的锁：

~~~c
top: 
    pthread_mutex_lock(L1);
    if (pthread_mutex_trylock(L2) != 0) { 
       pthread_mutex_unlock(L1); 
       goto top;
    }
~~~

上面的调用方式，当发现锁已经被调用，程序可以再次返回等待锁，也可以做一些其它事情。有人可能已经发现了，当锁的调用顺序相反时，按照上面的程序，依然可能出现类似“死锁”的现象，这种我们称之为活锁，因为程序并没有进入调用陷阱，而是依然不断运行着。虽然有一些问题，但是这种方法并没有真正添加抢占(从拥有锁的线程强制拿走锁的行为)，而是使用trylock方法，允许开发人员以一种优雅的方式退出锁的所有权(即抢占自己的所有权)。因此还是比较实用的。

第四个是Mutual Exclusion，最后一个比较根本，完全避免互斥的需要。通常，我们知道这是困难的，因为我们希望运行的代码确实有临界区。那么我们能做什么呢？Herlihy有这样一个想法，即人们可以设计完全没有锁的各种数据结构，具体的说，使用强大的硬件指令，我们确实已经构建了一些不需要锁的并发程序。

![](http://1.14.100.228:8002/images/2022/03/07/20220308101413.png)

这种方法最大问题是复杂，构建一个有用的列表需要的不仅仅是一个列表插入，毫无疑问，构建一个可以以无锁的方式插入、删除和执行查询的列表并不简单。

当然也有一些其它方向的思路，有时候这些想法对解决问题有意外的效果。

我们可以通过调度的方式来避免死锁，假如我们知道各种线程在执行时可能会抓住哪些锁，那么就可以以一种保证不会发生死锁的方式调度这些线程。

<img src="http://1.14.100.228:8002/images/2022/03/07/20220308101736.png" style="zoom:80%;" />

具体的方式我们不讨论，但是可以发现，假如能够实现的话，这种方法虽然能够避免死锁，但是会付出很大性能开销的代价。

最后一种通用的策略是允许偶尔发生死锁，然后在检测到死锁后采取一些行动。例如，如果一个操作系统每年冻结一次，你只需重启它，然后继续运行即可。如果死锁很少发生，那么这种非解决方案确实是非常实用的。

许多数据库系统采用死锁检测和恢复技术。死锁检测器定期运行，构建资源图(事务等待图)并检查是否有闭环。在出现闭环(死锁)的情况下，则需要重新启动系统。

对于死锁问题，在实践中，最好的解决方案是谨慎地开发获取锁的顺序，从而从一开始就防止死锁的发生。无阻塞的方法也很有前途，因为一些无阻塞的数据结构现在正被应用到常用的库和关键系统中，包括Linux。然而，它们缺乏通用性。

也许最好的解决方案是开发新的并发编程模型：在像MapReduce(来自google)这样的系统中，程序员可以描述某些类型的并行计算，而不需要任何锁。锁本身就有问题；也许我们应该避免使用它们，除非我们真的必须这样做。

## 基于事件的并发

这一节我实在是看不太懂:cry:，所以只能暂时记一下。

我们讨论了各种基于线程的并发的原理，也了解了它们的优缺点，现在的问题。实际上还有一种**基于事件的并发（events-based-concurrency）**。假设在单核的情况下，我们可以用一个简单的方式实现并发——循环。当服务启动后，会有一个无限循环，在循环中我们看是否有事件，假如有则进行处理。

~~~c
while (1) {
    events = getEvents();
    for (e in events)
    processEvent(e);
}
~~~

现在问题是当我们获取到events的时候，我们怎么知道这个event是什么类型，是I/O操作还是网络请求？更进一步，我们怎么知道一个event来了呢？

这些问题恐怕我现在是解决不了。

**注：**阻塞接口是指那些需要暂停进程知道返回的接口，非阻塞接口则是那些可以不需要等待就可以返回的接口，真正的处理在后台进行。































































 





