## 模型文件保存

**模型保存与调用：**

**1.pickle与joblib：**

* 原理：通过函数保存对象在文件中，保存对象即指将传入类的**self**当前状态保存在文件中，以便于在另一个文件将该状态赋予另一个对象中

* 保存模型

  >   joblib.dump(object, "modelname.m")  or   pickle.dump(obj, file)

* 调用本地模型

  >  object = joblib.load("modelname.m")   or   pickle.load(file)    

​       tip: file means the file object and the way to open it

## 损失函数

简单定义：已知的标准与自动拟合的标准相差的程度的定量表达，用于比较两个模型差距有多少

根据优化函数不同，可将损失函数分为四种思路，分别是经验风险最小化、结构风险最小化、最大化似然估计、最大化后验概率

模型 ![[公式]](https://www.zhihu.com/equation?tex=f%28X%29) 关于训练数据集的平均损失称为经验风险。经验风险最小化（Empirical Risk Minimization，ERM）认为经验风险最小的模型是最优的模型，公式如下：
$$
\min _{f \in b} \frac{1}{N} \sum_{i=1}^{N} L\left(y_{i}, f\left(x_{i}\right)\right)
$$
结构风险在经验风险上加上表示模型复杂度的正则化项或罚项。结构风险最小化（Structural Risk Minimization，SRM）是为了防止过拟合而提出来的， ![[公式]](https://www.zhihu.com/equation?tex=J%28f%29) 是模型的复杂度，公式如下：
$$
\min _{f \in b} \frac{1}{N} \sum_{i=1}^{N} L\left(y_{i}, f\left(x_{i}\right)\right)+\lambda J(f)
$$
最大化似然估计（Maximum Likelihood Estimation，MLE）是一种**参数**估计方法，利用已知的样本分布，找到最有可能（即最大概率）**导致这种分布的参数值**；或者说什么样的参数才能使我们观测到目前这组数据的概率最大

最大后验估计（Maximum A Posteriori estimation, MAP）也是一种参数估计方法，与MLE类似。最大区别是，MAP在其中融入了要估计量的先验分布，故最大后验估计可以看做规则化的最大似然估计

两种关系：

* 当模型是**条件概率**分布、损失函数是**对数损失函数**时，经验风险最小化等价于最大似然估计
* 当模型是**条件概率**分布、损失函数是**对数损失函数**、模型复杂度有模型的**先验概率**表示时，结构风险最小化等价于最大后验概率估计

#### **简单损失函数**

**最小二乘法：**直觉上，只要能够表示两个模型的输出相差程度的大小就能够满足我们的要求，于是有
$$
loss=\sum_{0}^{all}|y_{i}-y|
$$
但是，绝对值并非任何情况下都可导，于是，可以用平方去替代它
$$
loss=\sum_{0}^{all}(y_{i}-y)^2
$$
但是最小二乘法在反向求梯度的时候非常麻烦，因此一般不采用最小二乘法作为损失函数

**极大似然估计：**

似然值：真实的情况已经发生，我们假设对应现实的有多种概率模型，通过这些概率模型算出的结果就叫似然值，有几个模型就有几个似然值。从数学层面可以看做是以下公式
$$
P(C_{1},C_{2},C_{3},...,C_{n}|\theta)=\prod_{1}^{n}P(C_{i}|\theta)
$$

对应在神经网络中，每一个神经网络都有独特的权重与偏重，可以看做是一种理想模型，它对于某种输入有相应似然值结果。从数学层面可以看做是以下公式。
$$
P(x_{1},x_{2},x_{3},...,x_{n}|W,b)=\prod_{1}^{n}P(x_{i}|W,b)
$$
极大似然估计：就是对某个特定W,b的神经网络的似然值求最大，通过极大似然值大小来表示模型与标准相差的程度大小，因此，肯定不能只看一个神经网络的输出，因此有
$$
\prod_{1}^{n}P(x_{i}|W,b)=\prod_{1}^{n}P(x_{i}|y_{i})
$$
伯努利分布：是一种**离散分布**，又称为 “0-1 分布” 或 “两点分布”。例如抛硬币的正面或反面，物品有缺陷或没缺陷，病人康复或未康复，此类满足「**只有两种可能，试验结果相互独立且对立**」的随机变量通常称为伯努利随机变量

x,y就分别是一种伯努利随机变量，概率分布方程为
$$
f(x)=p^x*(1-p)^{1-x}
$$
由此，我们表示出了神经网络模型似然值的可迭代式

$$
\prod_{1}^{n}P(x_{i}|y_{i})=\prod_{1}^{n}y_{i}^{x_{i}}*(1-y_{i})^{1-x_{i}}
$$
因为对比连乘，连加更加便于计算，而log运算具有单调不变性，因此我们对似然值做一次log运算
$$
log(\prod_{1}^{n}y_{i}^{x_{i}}*(1-y_{i})^{1-x_{i}})=\sum_{1}^{n}log(y_{i}^{x_{i}}*(1-y_{i})^{1-x_{i}})=\sum_{1}^{n}(x_{i}*log(y_{i})+(1-x_{i})*log(1-y_{i}))\\极大似然值=max(\sum_{1}^{n}(x_{i}*log(y_{i})+(1-x_{i})*log(1-y_{i})))
$$
至此，我们将似然值这个概率概念设计成可以用于表示模型相差程度的函数，即把它变成为损失函数了

**交叉熵损失：**

先将模型换成熵，再用

信息量：我们设定一个函数，可以用信息量这个抽象概念来定量，即
$$
f(x):=信息量
$$
接下来的衍生概念都要使得这个定义能够在体系中自洽

接下来通过现实例子来尝试能不能推出f(x)的自洽的数学表达式，抽象的讲，对于两件能够连续发生的事情，（信息量的概念只能衡量这种例子吗？）例如小明在桂电踢球，踢到决赛的概率是a，踢到冠军的概率是b，而直接踢到冠军的概率是a*b，因为两件事的信息量是一样的，那么需要有
$$
f(a*b)=f(a)+f(b)
$$
这是一个非常明显的log运算，即
$$
f(x):=log_{n}x
$$
明显的，x这个概率越低，信息量越大。而n是一种量纲，事件的信息量数值大小随n的变化而变化，但是实际含义不变，故我们把n定义为2，方便思考，即实际上：
$$
f(x)=-log_{2}x
$$
熵：衡量一个概率模型（系统）的不确定程度（直接看出结果的可能性），越大概率的事件对系统不确定程度的贡献越小，由此，可以把熵定义为
$$
H_{熵}(P):=E_{期望}(P_{f})=\sum_{i=1}^{m} p_{i} \cdot f\left(p_{i}\right)=\sum_{i=1}^{m} p_{i}\left(-\log _{2} p_{i}\right)=-\sum_{i=1}^{m} p_{i} \cdot \log _{2} p_{i}
\
$$
至此，我们把熵这个概念量化了。而我们的目标是将概率模型和人脑内模型做比较，是否可以直接比较两个模型的熵呢。答案是不行的，因为人脑模型熵无法计算。因此，我们需要一种能够不直接求熵而能够定量比较两个模型的熵差距的方法

KL散度：Kullback-Leibler Divergence，即 K-L散度 ，是一种量化两种概率分布P和Q之间差异的方式，又叫**相对熵** KL散度能帮助我们度量使用一个分布来近似另一个分布时所损失的信息量，具体定义是：
$$
\begin{array}{l}
\boldsymbol{D}_{K L}(\boldsymbol{P} \| \boldsymbol{Q}) \\
:=\sum_{i=1}^{m} p_{i} \cdot\left(f_{Q}\left(\boldsymbol{q}_{i}\right)-f_{p}\left(p_{i}\right)\right) \\
=\sum_{i=1}^{m}{p}_{i} \cdot\left(\left(-\log _{2} \boldsymbol{q}_{i}\right)-\left(-\log _{2} p_{i}\right)\right) \\
=\sum_{i=1}^{m}{p}_{i} \cdot\left(-\log _{2} \boldsymbol{q}_{i}\right)-\sum_{i=1}^{m} p_{i} \cdot\left(-\log _{2} p_{i}\right)
\end{array}
$$
这一段定义的文字描述是，以P为基准，P的信息量是确定但未知的，求Q与P之间所有事件的熵的差值的在P系统内的期望，这里比较绕，但是KL散度就是这个概念，由此可以得到Q去拟合P的话会损失多少信息量。而通过吉布斯不等式我们可以得知，KL散度一直是大于0的

交叉熵：从上面我们可以看出，交叉熵就是KL散度左边的部分。而将这个数学中交叉熵的定义应用于概率模型中需要一些变换，首先，m是在P模型中所有事件的总数，Pi可以直接用输入的训练集标签，值为0、1。而Qi需要考虑一下，因为Qi的值是一个浮点数值，代表对输入的置信度的大小，它与训练集标签是不对应的，因此我们需要把Qi进行展开，分为训练集标签是1和训练集标签是0的情况，具体公式为：
$$
\begin{array}{l}
\boldsymbol{H}(\boldsymbol{P}, \boldsymbol{Q}) \\
=\sum_{i=1}^{m} p_{i} \cdot\left(-\log _{2} q_{i}\right) \\
=\sum_{i=1}^{n} x_{i} \cdot\left(-\log _{2} q_{i}\right) \\
=-\sum_{i=1}^{n}\left(x_{i} \cdot \log _{2} y_{i}+\left(1-x_{i}\right) \cdot \log _{2}\left(1-y_{i}\right)\right)
\end{array}
$$
至此，H成为了可以定量描述P，Q两个模型的差异的表达式

（在这里，交叉熵的函数形式与极大似然估计的函数形式非常像，但是极大似然估计的函数形式是通过数学直觉进行推导的，本身没有定义支撑，而交叉熵损失函数是通过定义一步步推导得到，具有量纲，更加严谨）

## 模型建立和验证

#### 交叉验证

交叉验证是在机器学习**建立模型**和**验证模型参数**时常用的办法。交叉验证，顾名思义，就是重复的使用数据，把得到的样本数据进行切分，组合为不同的训练集和测试集，用训练集来训练模型，用测试集来评估模型预测的好坏。

**简单交叉验证**

对于总数据集D，随机挑选固定比例的训练集和验证集，对一个或多个模型进行训练。得到挑选出效果更好的模型和相应的那组参数

**S折交叉验证**

和第一种方法不同，S折交叉验证会把样本数据随机的分成S份，每次随机的选择S-1份作为训练集，剩下的1份做测试集。当这一轮完成后，重新随机选择S-1份来训练数据。若干轮（小于S）之后，选择损失函数评估最优的模型和参数



















