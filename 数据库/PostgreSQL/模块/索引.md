# B+树索引

来源：[PostgreSQL BTree(B-Link-Tree变种) 索引基本实现原理 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/639226810)

B树和相关变种是专门用于构建内存索引查找存储于磁盘的数据，B树本质就是存储kv对的自平衡多叉树，具有以下性质(假设度为2)：

1. 每一条从root 根节点 到 leaf 叶子 节点的路径高度都是完全相同的。
2. root 节点要么是叶子节点（只有一个节点的情况），要么拥有两个子节点
3. 除了root 根节点之外的节点至少包含 t - 1 个key 或者 upper ( m /2 ) - 1个key
4. 除了 root 节点 以及 leaf 节点之外的内部节点 至少包含 t 个子节点，最多包含2*t个子节点，或者说 内部节点的子节点个数等于其当前包含的 key 个数 + 1
5. 每一个节点内部最多存储 2t - 1 个key
6. 节点内部的key 是升序排列
7. 大多数kv对都在叶子节点，也允许内部节点保存kv对，叶子节点有n个key，就有n+1个指针

度越大，树就越宽，索引深度就越浅

degree t = 2 的 BTree 形态如下：

![img](https://pic2.zhimg.com/80/v2-6d96bedc46a1794b2aa48ff4b71bd7d5_720w.webp)

基于B树延展出了B+树，它具有减少IO和便于顺序遍历访问的场景两大好处

比如 一个 BTree 的 t = 512，也就是一个节点内部最多存储 1023个key，这样的三层B+Tree 能够保存 10亿个key，如果只有root节点被存储到内存，查找一个key的数据也只需要两次随机IO 加载到key所在的叶子节点的pages，并在内存中二分查找即可；当然实际 root 节点 以及 第一层的key肯定都能被存储到内存中，这样的查询效率会更高。

一个degree 为2 的B+Tree的形态如下：

![img](https://pic4.zhimg.com/80/v2-8f5a4344be24518c7aae3821c5fa7f4b_720w.webp)

B-linked-Tree在B+Tree的基础上解决了并发访问性能的问题，具体的，B-Link-Tree 在B+Tree的基础上又增加了两个性质：

1. 为每一个内部节点 新增了一个指向兄弟节点的右向指针。
2. 为每一个内部节点引入一个额外的key (high-key)，它是当前节点以及所有子节点中最大的key。

B-Link-Tree 的形态如下：

![img](https://pic3.zhimg.com/80/v2-6bbb0288559fc6e8189c9c0c79b3318a_720w.webp)

**插入操作**

对于要插入的key，首先会二分找到叶子节点插入，然后判断是否分裂，如果要分裂则选择中间key进行level up(自身有可能留也有可能不留)放入到父节点，再进行同样的判断，在此过程中同步更新key number和high-key等中间量

- max childens = 4
- internal节点 min childens = 2
- max keys = 2*t - 1 = 3
- min keys = t-1 = 1

**PostgreSQL BTree结构**

在PG中，如果查询不走索引，就需要将整个表文件按照磁盘上的顺序载入缓存中，然后一个个page的扫描得到结果

在PG中整个 BTree 作为 Index ，其基本的形态如下：

![img](https://pic1.zhimg.com/80/v2-8ed152d106ea195db87fae78962c6334_720w.webp)

- PG 中的 BTree 是一个略有变动的 B-Link-Tree，即内部节点增加了左向指针。
- 基本的BTree 索引持久化形态是和 Heap 表基本一样（除了唯一的Meta page），每一个节点保存到一个page，节点内的key 已经 子节点保存的value都会作为index tuple 保存到该 page中。
- Meta page 用来保存当前BTree 的元数据，也是索引page的第0页
- Inner Node(page) 内部节点，其index-tuple 中 仅保存key 以及指向子节点的指针
- Leaf Node(page) 叶子节点，是BTree 索引的最底层，其内部的 index-tuple 保存的是key 以及 指向 数据tuple的 tid。通过 tid 能够访问这个key 对应的实际数据。
- 每一个节点所在的page 内部最后有一部分 Special space空间，保存了当前节点或者说 index-page 的元数据，其是通过 `BTPageOpaqueData`表示。主要保存这个 page 左右方向指针、page所在 BTree 层级、以及当前页面的状态（叶子节点/内部节点/根节点/删除页面......）

PG中分裂的条件不是依据 每一个节点内部 key的个数，而是节点所在page的大小，比如page 没有插入下一个tuple 的空间了，则才会触发分裂。

索引的key：在PostgreSQL中，B树索引的键（key）是一个包含一个或多个列值的数据结构。如果列值相同，B树索引将使用附加的排序规则来处理它们，例如使用TID确保键值唯一

# 哈希索引

**索引结构**

PG的哈希和理论的哈希非常接近，哈希之后分桶

当向索引中插入时，我们会对列值计算Hash值。PG中的Hash函数通常返回一个整型，它的范围大约为232 ≈ 42亿。桶的数量初始为2，随着数据量的增加而动态增加。桶的编号可以通过对Hash值做位运算得出，这个桶就是存放TID的桶。

但这还不够，因为不同的列值对应的TID可能会被存放到相同的桶中。我们应该怎么办呢？一种可能的实现方式是把原始的列值和TID一起存放在桶中，但这将大大增加索引所占的空间。因此，为了节省空间，桶中存放的是列值的Hash值，而不是直接存放列值。

当在索引中查找时，我们对列值计算Hash值，得到桶的编号。然后，遍历桶中的元素，仅返回相应Hash值得TID。这可以高效的完成，因为<Hash值, TID>被有序的存储。

然而，有时两个不同的key不仅被存储在相同的桶中，而且它们具有相同的Hash值。因此，AM会让索引引擎重新检查（索引引擎可以在检查可见性时顺便做这件事）索引条件，用来确认TID是否真的满足索引条件。

每次索引空间增加时，PG生成的桶数都是上次生成桶数的2倍。为了避免一次性分配大量页面，PG 10扩展空间时更加平缓。至于溢出页，则按需分配，被位图页跟踪。位图页也按需分配。

实际在创建索引的过程中，如果表上有数据，不会从 2 个初始 bucket 开始不断通过 split 来扩展 bucket 的数量，而是预估需要的 bucket 的数量，然后一次分配足够的 bucket。

当需要新增 hash bucket 时，对当前存在的 bucket 执行 “split”，原来再这个执行 split 的 bucket 中的某些 index tuples 需要根据更新后的 key-to-bucket-number 的映射关系被转移到新的 hash bucket 中。

**哈希索引页**

[![img](https://www.mengqingzhong.com/wp-content/uploads/2020/11/wp_editor_md_1d8ae1f6a217301c34816c44583dc58f.jpg)](https://www.mengqingzhong.com/wp-content/uploads/2020/11/wp_editor_md_1d8ae1f6a217301c34816c44583dc58f.jpg)

如上图所示，Hash索引共使用了4种页面（灰色矩形）。

- 元页面 —— 第0页，存储索引的元信息
- 桶页 —— 索引中主要的页，存储<Hash值, TID>键值对
- 溢出页 —— 和桶页的结构相同，当一个桶页的空间不够时被使用
- 位图页 —— 跟踪溢出页的使用情况，表示哪些溢出页空闲且可以被其它桶使用

索引页中向下的箭头表示TID，指向表中的行。

同一个 page 内的索引数据，按照 hash code 排序以支持在 page 内使用二分查找，加快查找速度。但 bucket 内不同的 page 之间是无序的。【实际同一个 page 内的 index tuple 也未必是有序的，index tuple 排序是有条件的。】
这部分可以参考代码中的注释部分，只有索引的大小超出 maintenance_work_mem 或可用 buffer 大小时才会排序。

hash 索引只能通过 reindex 命令来回收空间。已经分配的 overflow page 可以回收被其他 bucket 再使用，但不会被归还给操作系统。也没有办法减少 hash bucket 的数量。

**哈希函数**

Postgres中哈希索引以列值作为key，以key的hash值+TID作为value，不同数据类型的列值对应不同的哈希函数，下面列几个基础类型的哈希函数

```
   opfamily_name    | opfamily_procedure 
--------------------+--------------------
 bool_ops           | hashchar
 bytea_ops          | hashvarlena
 char_ops           | hashchar
 cid_ops            | hashint4
 date_ops           | hashint4
 float_ops          | hashfloat4
 float_ops          | hashfloat8
 integer_ops        | hashint2
 integer_ops        | hashint4
 integer_ops        | hashint8
```

这些函数都是系统内置函数，可以直接select调用

~~~sql
postgres> select hashtext('one');
 hashtext  
-----------
 127722028
(1 row)
~~~

**Hash索引的属性**

哈希索引方法、哈希索引本身和哈希索引列分别有一些属性

```
     name      | pg_indexam_has_property
---------------+-------------------------
 can_order     | f
 can_unique    | f
 can_multi_col | f
 can_exclude   | t

     name      | pg_index_has_property
---------------+-----------------------
 clusterable   | f
 index_scan    | t
 bitmap_scan   | t
 backward_scan | t

        name        | pg_index_column_has_property 
--------------------+------------------------------
 asc                | f
 desc               | f
 nulls_first        | f
 nulls_last         | f
 orderable          | f
 distance_orderable | f
 returnable         | f
 search_array       | f
 search_nulls       | f
```

通过比较两个列值的Hash值的大小，无法推断出两个列值谁大谁小。因此，通常来讲，Hash索引仅支持等值查询。

```sql
select   opf.opfname AS opfamily_name,
         amop.amopopr::regoperator AS opfamily_operator
from     pg_am am,
         pg_opfamily opf,
         pg_amop amop
where    opf.opfmethod = am.oid
and      amop.amopfamily = opf.oid
and      am.amname = 'hash'
order by opfamily_name,
         opfamily_operator;
```

Copy

```
   opfamily_name    |                     opfamily_operator                      
--------------------+------------------------------------------------------------
 abstime_ops        | =(abstime,abstime)
 aclitem_ops        | =(aclitem,aclitem)
 array_ops          | =(anyarray,anyarray)
 bool_ops           | =(boolean,boolean)
 bpchar_ops         | =(character,character)
 bpchar_pattern_ops | =(character,character)
 bytea_ops          | =(bytea,bytea)
 char_ops           | =("char","char")
 cid_ops            | =(cid,cid)
 date_ops           | =(date,date)
 enum_ops           | =(anyenum,anyenum)
 float_ops          | =(real,real)
 float_ops          | =(double precision,double precision)
 float_ops          | =(real,double precision)
 float_ops          | =(double precision,real)
 integer_ops        | =(integer,bigint)
 integer_ops        | =(smallint,smallint)
 integer_ops        | =(integer,integer)
 integer_ops        | =(bigint,bigint)
 integer_ops        | =(bigint,integer)
 integer_ops        | =(smallint,integer)
 integer_ops        | =(integer,smallint)
 integer_ops        | =(smallint,bigint)
 integer_ops        | =(bigint,smallint)
 interval_ops       | =(interval,interval)
 jsonb_ops          | =(jsonb,jsonb)
 macaddr8_ops       | =(macaddr8,macaddr8)
 macaddr_ops        | =(macaddr,macaddr)
 name_ops           | =(name,name)
 network_ops        | =(inet,inet)
 numeric_ops        | =(numeric,numeric)
 oid_ops            | =(oid,oid)
 oidvector_ops      | =(oidvector,oidvector)
 pg_lsn_ops         | =(pg_lsn,pg_lsn)
 range_ops          | =(anyrange,anyrange)
 reltime_ops        | =(reltime,reltime)
 text_ops           | =(text,text)
 text_pattern_ops   | =(text,text)
 time_ops           | =(time without time zone,time without time zone)
 timestamp_ops      | =(timestamp without time zone,timestamp without time zone)
 timestamptz_ops    | =(timestamp with time zone,timestamp with time zone)
 timetz_ops         | =(time with time zone,time with time zone)
 uuid_ops           | =(uuid,uuid)
 xid_ops            | =(xid,xid)
(44 rows)
```

因此，Hash索引不能返回有序的结果（can_order、orderable）。基于相同的原因，Hash索引不处理NULL值；“相等”对NULL值来说没有意义（search_nulls）。

**并发控制**





# GIN索引





# BRIN索引

到底BRIN 索引是怎么做到的，大幅度降低索引的存储空间，并且还保证超高的索引查询中的查询率。

原因，BRIN 索引是一种有损索引，这个索引的简称 Block Range Index， 而BRIN 索引产生的主要原因也是为了一些 “超级大表的索引”，试想一下，你有一张6亿条记录的表，很可能你的索引就是几个G ，而这样的索引在查询中，其实随着数据量的增大，性能是线性下降的。

而BRIN 所以存储的数据并不是普通索引那样的 BTREE 的数据，而是存储元祖数据，以及相关数据的页面信息，通过这些信息，大大减少了存储数据的空间，而在判断数据是否符合条件的情况下，则比BTREE 索引要付出更多的过滤和对比的过程，但相对他超高的性价比，对于大表， 有序型的数据的索引的建立，BRIN 索引是值得被考虑和使用的。

