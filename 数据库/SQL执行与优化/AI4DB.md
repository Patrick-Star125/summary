现有的执行优化方案在启发式方法上都差不多，至少在非定制的开源数据库之中，启发式方法已经被证明其作用是有限的。在这样的背景下，基于代价的优化方法是成为当前研究的主流，基于代价优化（CBO）原理是计算所有执行路径的代价，并挑选代价最小的执行。

## 基数估计

计算代价的重要指标是基数，基数估计（cardinality estimation）就是估计基数的一类方法的统称。

基数估计的作用主要可概括成如下两个方面：

 （1）基数估计是数据库查询优化的重要一环。由于子查询的基数代表了中间结果的大小，因此现有的大多数基于代价的查询优化技术对子查询计划代价的估计**强烈依赖对子查询基数的估计**。一个优秀的基数估计模型能帮助优化器更好地选择合适的执行计划。

 （2）基数估计可以帮助回答一些只需要知道结果数量的查询。例如某个用户可能想知道全中国有多少大学生学习计算机专业，这个查询只关心结果的数目而不需要知道每条结果的具体值。对这样的查询我们可以通过基数估计的方法**快速返回结果大小的近似值**。

基数估计是一个重要且较为困难的问题，几十年来一直有研究者尝试用各种方法和技巧提升估计的准确性和稳健性，现有的方法可以分为如下几类：

**目前方法的分类**

基数估计是一个重要且较为困难的问题，几十年来一直有研究者尝试用各种方法和技巧提升估计的准确性和稳健性，现有的方法可以分为如下几类：

![img](https://img-blog.csdnimg.cn/img_convert/06b4323d3db4c9f82aaaac3606b36a2f.png)

总体上可以分类传统型方法和基于[机器学习](https://so.csdn.net/so/search?q=机器学习&spm=1001.2101.3001.7020)的方法。下面会选取其中具有代表性的几个工作简要介绍。

**传统型基数估计方法**

传统型基数估计方法大体上可以分为基于概要(synopsis-based)和采样(sampling)的两大类方法。

基于概要的基数估计方法会预先**收集数据库的一些统计信息**，并**基于独立性等简单假设**，能够方便**快速地**求解查询基数。

例如基于直方图(histogram)的方法，其对数据表中**每一列总结成一张等宽(equal width)或等深(equal depth)的直方图**，最后根据查询条件，基于列与列之间相互独立的假设，估计出查询结果的大小。当然有时这样的独立性假设效果不好，便可根据多维直方图(multi-dimensional histogram)的方法求解。

数据画像(sketching)也属于基于概要的基数估计方法，其使用**bitmap或哈希的方法**，估计数据库中互不相同的元素个数，比较适合流式数据的场景。更新的一类数据画像的方法如loglog、hyperloglog等，更加注重节约内存和提升估计的稳健性。

基于采样的方法会从原始数据表中**随机抽取一定比例或者一定数量的元组**，最终根据在采样集上执行查询后的结果大小除以相应的缩放比例便可得到查询在原数据库的基数估计。基于采样的方法在采样策略较好、**能反映大部分数据分布的情况下效果较好**，但也很容易由于采样的随机性无法产生采样集上匹配结果的情况，便有研究者提出了一种基于索引的采样方法(index-based sampling)，其在多表连接时，会根据查询的连接条件选择要采样的范围，**能减少采样出现零结果的情况**，具体图示如下：


![img](https://img-blog.csdnimg.cn/img_convert/89fd4edddadae640699dac88b146b2b0.png)

**查询驱动的学习型基数估计方法**

由于基数估计可以视为“查询”到”基数值”的回归问题(当数据库没有更新时)，故我们可以将监督学习的技巧迁移到本问题上，直接**学习查询到基数的对应关系**。一般的查询驱动方法的工作流程如下所示：

![img](https://img-blog.csdnimg.cn/img_convert/718f4dde24997a80ca96d5f93a983ba6.png)

其难点主要在于训练数据的获取和查询语句的表示两方面。

通常而言，当数据库给定时，我们可以假设查询框架(schema)是已知的（例如，某两个表会根据哪些列做连接等），由此我们可以随机产生一些查询语句，将这些语句真实运行之后，我们便得到了这些查询的真实基数，这就构成了训练模型需要的训练数据。当然也可以根据数据库的查询日志直接获取查询。需要注意的是，训练数据一定要有代表性，否则模型不能学习到工作环境中常见的查询模式到基数的对应，会影响到预测的准确性。

查询语句的表示主要由查询表、谓词条件、连接条件等决定，更复杂的情况包括含正则表示式之类的“like”查询。

这是一个很新的领域，因此可参考的方法不多。

**数据驱动的学习型基数估计方法**

与查询驱动类的方法不同，数据驱动的基数估计方法为无监督的一类方法，直接从数据表中学习数据的分布，因此训练较为简单。

在工作 [5] 中，作者使用核密度估计(kernel density estimation, KDE)的方法估计查询基数。其想法为在数据表中随机抽取若干元组，这样查询点和采样元组越靠近，那该查询有结果的可能性就会较大。作者使用了高斯核，并用可学习的参数控制概率密度的分散程度。对于数据库更新场景，作者使用蓄水池抽样(reservoir sampling)应对数据插入；通过监测去除某个采样元组对估计效果的影响应对数据删除（即如果删去某个元组能提升估计效果，则将其删去）。由于计算只需要对每个采样元组计算概率再相加，故可以通过GPU加速计算。作者也在之后的研究中，将核密度估计的方法拓展到多表连接的基数估计 [6]。下图展示了核密度估计的主要思想：

![img](https://img-blog.csdnimg.cn/img_convert/9f91341a047c3fa1f37a104173bf1d93.png)

还有一类使用自回归模型估计基数的方法。在工作[7]中，作者提出了Naru模型，在训练过程中还融合了采样和Mask技巧，能够提升模型的准确性。作者其后也将该方法拓展到多表连接的情形 [8]。

另外一类数据驱动的方法使用了SPN(sum product network)。主要思想为通过对数据表做横向划分（例如使用KMeans等聚类方法），使元组各列在分割后的数据上近似独立，这样便可通过在每一列上构建直方图或线性回归模型估计基数。DeepDB [9] 是一个使用SPN的基数估计方法，近年来也有对SPN的改进，如FLAT [10]，其将数据表的各类分为强相关和弱相关两类，再进一步使用SPN方法划分数据表。下图展示了DeepDB是如何计算“年龄小于30岁的欧洲顾客人数”的：

![img](https://img-blog.csdnimg.cn/img_convert/0ef35001d5ad5dc8c089a1d8650b1274.png)

**目前的困难和未来研究方向**

第一点，尽管目前的方法能比传统方法更准确，但也耗费了大量时间训练模型，如何在准确率和效率之间取舍是应用这些方法的数据库使用者需要考虑的问题。

第二点，大部分的模型都很难适应更新环境。当有大量数据插入或删除是，这些模型很难追踪这些改动，因此需要重新训练，这在OLTP环境中是需要改进的。

第三点，这些模型在多表连接的场景下估计效果仍然很差。多表连接时，不同表之间的依赖性难以捕捉，给基数估计带来了较大的困难。

